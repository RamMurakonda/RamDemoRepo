{
	"$schema": "http://schema.management.azure.com/schemas/2015-01-01/deploymentTemplate.json#",
	"contentVersion": "1.0.0.0",
	"parameters": {
		"factoryName": {
			"type": "string",
			"metadata": "Data Factory name",
			"defaultValue": "ADFdemoramm"
		},
		"LinkedService_Sql_password": {
			"type": "secureString",
			"metadata": "Secure string for 'password' of 'LinkedService_Sql'"
		},
		"Linkedservice_storagedemoramm_connectionString": {
			"type": "secureString",
			"metadata": "Secure string for 'connectionString' of 'Linkedservice_storagedemoramm'"
		},
		"LinkedService_Sql_properties_typeProperties_server": {
			"type": "string",
			"defaultValue": "mydbserver.windowa.ds.net"
		},
		"LinkedService_Sql_properties_typeProperties_database": {
			"type": "string",
			"defaultValue": "@{linkedService().DbName}"
		},
		"LinkedService_Sql_properties_typeProperties_userName": {
			"type": "string",
			"defaultValue": "ramm"
		},
		"trigger1_properties_pipeline2 - SQL Database_parameters_SourceTable": {
			"type": "string",
			"defaultValue": "Table1"
		},
		"trigger1_properties_pipeline2 - SQL Database_parameters_DbNamefromPipeline": {
			"type": "string",
			"defaultValue": "TestDB"
		},
		"trigger1_properties_pipeline2 - SQL Database_parameters_DestinationTable": {
			"type": "string",
			"defaultValue": "Table2"
		}
	},
	"variables": {
		"factoryId": "[concat('Microsoft.DataFactory/factories/', parameters('factoryName'))]"
	},
	"resources": [
		{
			"name": "[concat(parameters('factoryName'), '/Pipeline 5 - Master Execute Pipeline')]",
			"type": "Microsoft.DataFactory/factories/pipelines",
			"apiVersion": "2018-06-01",
			"properties": {
				"activities": [
					{
						"name": "Pipeline 5 - Master Execute Pipeline",
						"description": "Executing the pipeline using execute pipeline activity",
						"type": "ExecutePipeline",
						"dependsOn": [],
						"policy": {
							"secureInput": false
						},
						"userProperties": [],
						"typeProperties": {
							"pipeline": {
								"referenceName": "pipeline1 - copying TXT File",
								"type": "PipelineReference"
							},
							"waitOnCompletion": true,
							"parameters": {}
						}
					}
				],
				"policy": {
					"elapsedTimeMetric": {}
				},
				"annotations": [],
				"lastPublishTime": "2024-06-16T05:43:15Z"
			},
			"dependsOn": [
				"[concat(variables('factoryId'), '/pipelines/pipeline1 - copying TXT File')]"
			]
		},
		{
			"name": "[concat(parameters('factoryName'), '/pipeline 13 - Executing Data Flow')]",
			"type": "Microsoft.DataFactory/factories/pipelines",
			"apiVersion": "2018-06-01",
			"properties": {
				"activities": [
					{
						"name": "Data flow1",
						"type": "ExecuteDataFlow",
						"dependsOn": [],
						"policy": {
							"timeout": "0.12:00:00",
							"retry": 0,
							"retryIntervalInSeconds": 30,
							"secureOutput": false,
							"secureInput": false
						},
						"userProperties": [],
						"typeProperties": {
							"dataflow": {
								"referenceName": "AlterRowDataflow",
								"type": "DataFlowReference",
								"parameters": {},
								"datasetParameters": {
									"source1": {},
									"sink1": {}
								}
							},
							"staging": {},
							"compute": {
								"coreCount": 8,
								"computeType": "General"
							},
							"traceLevel": "Fine"
						}
					}
				],
				"policy": {
					"elapsedTimeMetric": {}
				},
				"annotations": [],
				"lastPublishTime": "2024-06-27T22:52:56Z"
			},
			"dependsOn": [
				"[concat(variables('factoryId'), '/dataflows/AlterRowDataflow')]"
			]
		},
		{
			"name": "[concat(parameters('factoryName'), '/pipeline1 - copying TXT File')]",
			"type": "Microsoft.DataFactory/factories/pipelines",
			"apiVersion": "2018-06-01",
			"properties": {
				"activities": [
					{
						"name": "Copy data1",
						"description": "Coping the data.txt file from the input folder to output folder in adfdemo container",
						"type": "Copy",
						"dependsOn": [],
						"policy": {
							"timeout": "0.12:00:00",
							"retry": 0,
							"retryIntervalInSeconds": 30,
							"secureOutput": false,
							"secureInput": false
						},
						"userProperties": [
							{
								"name": "Source",
								"value": "adfdemo/input/data.txt"
							},
							{
								"name": "Destination",
								"value": "adfdemo/output/data.txt"
							}
						],
						"typeProperties": {
							"source": {
								"type": "BinarySource",
								"storeSettings": {
									"type": "AzureBlobStorageReadSettings",
									"recursive": true
								},
								"formatSettings": {
									"type": "BinaryReadSettings"
								}
							},
							"sink": {
								"type": "BinarySink",
								"storeSettings": {
									"type": "AzureBlobStorageWriteSettings"
								}
							},
							"enableStaging": false
						},
						"inputs": [
							{
								"referenceName": "InputDataDataSet",
								"type": "DatasetReference",
								"parameters": {}
							}
						],
						"outputs": [
							{
								"referenceName": "OutputDataDataset",
								"type": "DatasetReference",
								"parameters": {}
							}
						]
					}
				],
				"policy": {
					"elapsedTimeMetric": {}
				},
				"annotations": [],
				"lastPublishTime": "2024-06-16T05:43:15Z"
			},
			"dependsOn": [
				"[concat(variables('factoryId'), '/datasets/InputDataDataSet')]",
				"[concat(variables('factoryId'), '/datasets/OutputDataDataset')]"
			]
		},
		{
			"name": "[concat(parameters('factoryName'), '/pipeline1')]",
			"type": "Microsoft.DataFactory/factories/pipelines",
			"apiVersion": "2018-06-01",
			"properties": {
				"description": "Refer to the data flow PerrameterDataFlow \nParametrizing the dataflow and running the dataflow thought pipeline parameter.\nin the pipeline we have created the new parameter named DEP and given this as the default value for the Data Flow parameter named DEPName. so, it will more user friendly to enter the parameter value for output ",
				"activities": [
					{
						"name": "Data flow1",
						"type": "ExecuteDataFlow",
						"dependsOn": [],
						"policy": {
							"timeout": "0.12:00:00",
							"retry": 0,
							"retryIntervalInSeconds": 30,
							"secureOutput": false,
							"secureInput": false
						},
						"userProperties": [],
						"typeProperties": {
							"dataflow": {
								"referenceName": "PerrametaringDataflow",
								"type": "DataFlowReference",
								"parameters": {
									"DEPName": {
										"value": "'@{pipeline().parameters.DEP}'",
										"type": "Expression"
									}
								},
								"datasetParameters": {
									"source1": {},
									"sink1": {}
								}
							},
							"staging": {},
							"compute": {
								"coreCount": 8,
								"computeType": "General"
							},
							"traceLevel": "Fine"
						}
					}
				],
				"policy": {
					"elapsedTimeMetric": {}
				},
				"parameters": {
					"DEP": {
						"type": "string"
					}
				},
				"annotations": [],
				"lastPublishTime": "2024-06-28T04:36:11Z"
			},
			"dependsOn": [
				"[concat(variables('factoryId'), '/dataflows/PerrametaringDataflow')]"
			]
		},
		{
			"name": "[concat(parameters('factoryName'), '/pipeline10 - Until Activity')]",
			"type": "Microsoft.DataFactory/factories/pipelines",
			"apiVersion": "2018-06-01",
			"properties": {
				"activities": [
					{
						"name": "Until1",
						"description": "in the Until loop \nThe flag value FileAvailabe variable tells file available or not available, the default value if false for the 1st time as the default value is false then it goes inside the loop and opens the activity's in the loop.\nthen using the GET METADATA we are getting the metadata of the file whether the file exists or not and then followed by the if condition, if its true  and file is available it sets the variable to True using the SETVERIABLE so the loop end here and followed by the copy data activity\n\nIF the value is false it means file is not available then it waits for 60 seconds before running the until loop again ",
						"type": "Until",
						"dependsOn": [],
						"userProperties": [],
						"typeProperties": {
							"expression": {
								"value": "@bool(variables('FileAvailable'))",
								"type": "Expression"
							},
							"activities": [
								{
									"name": "Get Metadata1",
									"type": "GetMetadata",
									"dependsOn": [],
									"policy": {
										"timeout": "0.12:00:00",
										"retry": 0,
										"retryIntervalInSeconds": 30,
										"secureOutput": false,
										"secureInput": false
									},
									"userProperties": [],
									"typeProperties": {
										"dataset": {
											"referenceName": "InputDataDataSet",
											"type": "DatasetReference",
											"parameters": {}
										},
										"fieldList": [
											"exists"
										],
										"storeSettings": {
											"type": "AzureBlobStorageReadSettings",
											"recursive": true,
											"enablePartitionDiscovery": false
										},
										"formatSettings": {
											"type": "BinaryReadSettings"
										}
									}
								},
								{
									"name": "If Condition1",
									"type": "IfCondition",
									"dependsOn": [
										{
											"activity": "Get Metadata1",
											"dependencyConditions": [
												"Succeeded"
											]
										}
									],
									"userProperties": [],
									"typeProperties": {
										"expression": {
											"value": "@activity('Get Metadata1').outputbinary()",
											"type": "Expression"
										},
										"ifFalseActivities": [
											{
												"name": "Wait1",
												"type": "Wait",
												"dependsOn": [],
												"userProperties": [],
												"typeProperties": {
													"waitTimeInSeconds": 60
												}
											}
										],
										"ifTrueActivities": [
											{
												"name": "Set variable1",
												"type": "SetVariable",
												"dependsOn": [],
												"policy": {
													"secureOutput": false,
													"secureInput": false
												},
												"userProperties": [],
												"typeProperties": {
													"variableName": "FileAvailable",
													"value": "True "
												}
											}
										]
									}
								}
							],
							"timeout": "0.00:02:00"
						}
					},
					{
						"name": "Copy data1",
						"description": "Copying the file after completing the until loop and found the metadata of that file ",
						"type": "Copy",
						"dependsOn": [
							{
								"activity": "Until1",
								"dependencyConditions": [
									"Succeeded"
								]
							}
						],
						"policy": {
							"timeout": "0.12:00:00",
							"retry": 0,
							"retryIntervalInSeconds": 30,
							"secureOutput": false,
							"secureInput": false
						},
						"userProperties": [
							{
								"name": "Source",
								"value": "adfdemo/input/data.txt"
							},
							{
								"name": "Destination",
								"value": "adfdemo/output/"
							}
						],
						"typeProperties": {
							"source": {
								"type": "BinarySource",
								"storeSettings": {
									"type": "AzureBlobStorageReadSettings",
									"recursive": true
								},
								"formatSettings": {
									"type": "BinaryReadSettings"
								}
							},
							"sink": {
								"type": "BinarySink",
								"storeSettings": {
									"type": "AzureBlobStorageWriteSettings"
								}
							},
							"enableStaging": false
						},
						"inputs": [
							{
								"referenceName": "InputDataDataSet",
								"type": "DatasetReference",
								"parameters": {}
							}
						],
						"outputs": [
							{
								"referenceName": "OutputFolderDataset",
								"type": "DatasetReference",
								"parameters": {}
							}
						]
					}
				],
				"policy": {
					"elapsedTimeMetric": {}
				},
				"variables": {
					"FileAvailable": {
						"type": "String",
						"defaultValue": "Flase"
					}
				},
				"annotations": [],
				"lastPublishTime": "2024-06-16T20:09:31Z"
			},
			"dependsOn": [
				"[concat(variables('factoryId'), '/datasets/InputDataDataSet')]",
				"[concat(variables('factoryId'), '/datasets/OutputFolderDataset')]"
			]
		},
		{
			"name": "[concat(parameters('factoryName'), '/pipeline11 - Web Activity API')]",
			"type": "Microsoft.DataFactory/factories/pipelines",
			"apiVersion": "2018-06-01",
			"properties": {
				"activities": [
					{
						"name": "Web1",
						"type": "WebActivity",
						"dependsOn": [],
						"policy": {
							"timeout": "0.12:00:00",
							"retry": 0,
							"retryIntervalInSeconds": 30,
							"secureOutput": false,
							"secureInput": false
						},
						"userProperties": [],
						"typeProperties": {
							"method": "GET",
							"headers": {},
							"disableCertValidation": false,
							"url": "\thttps://dummy.restapiexample.com/api/v1/employees"
						}
					}
				],
				"policy": {
					"elapsedTimeMetric": {}
				},
				"annotations": [],
				"lastPublishTime": "2024-06-16T20:53:00Z"
			},
			"dependsOn": []
		},
		{
			"name": "[concat(parameters('factoryName'), '/pipeline12 - Web Activity API post')]",
			"type": "Microsoft.DataFactory/factories/pipelines",
			"apiVersion": "2018-06-01",
			"properties": {
				"activities": [
					{
						"name": "Web1",
						"type": "WebActivity",
						"dependsOn": [],
						"policy": {
							"timeout": "0.12:00:00",
							"retry": 0,
							"retryIntervalInSeconds": 30,
							"secureOutput": false,
							"secureInput": false
						},
						"userProperties": [],
						"typeProperties": {
							"method": "POST",
							"headers": {
								"Content-type": "Application/json"
							},
							"url": "\thttps://dummy.restapiexample.com/api/v1/create",
							"body": {
								"name": "test",
								"salary": "123",
								"age": "23"
							}
						}
					}
				],
				"policy": {
					"elapsedTimeMetric": {}
				},
				"annotations": [],
				"lastPublishTime": "2024-06-16T21:00:03Z"
			},
			"dependsOn": []
		},
		{
			"name": "[concat(parameters('factoryName'), '/pipeline14 -  Executing Power Query')]",
			"type": "Microsoft.DataFactory/factories/pipelines",
			"apiVersion": "2018-06-01",
			"properties": {
				"activities": [
					{
						"name": "Power Query1",
						"type": "ExecuteWranglingDataflow",
						"dependsOn": [],
						"policy": {
							"timeout": "0.12:00:00",
							"retry": 0,
							"retryIntervalInSeconds": 30,
							"secureOutput": false,
							"secureInput": false
						},
						"userProperties": [],
						"typeProperties": {
							"dataflow": {
								"referenceName": "Powerquery 2  - Merge Queries",
								"type": "DataFlowReference",
								"datasetParameters": {
									"CustomersDataset": {},
									"OrdersDataset": {},
									"UserQueryOutputDatasetCSVfiles": {}
								}
							},
							"staging": {},
							"compute": {
								"coreCount": 8,
								"computeType": "General"
							},
							"queries": [
								{
									"queryName": "UserQuery",
									"dataflowSinks": [
										{
											"name": "UserQueryOutputDatasetCSVfiles",
											"dataset": {
												"referenceName": "OutputDatasetCSVfiles",
												"type": "DatasetReference",
												"parameters": {}
											},
											"script": "sink(allowSchemaDrift: true,\n\tvalidateSchema: false,\n\tpartitionFileNames:['Power Query - Merging Quires - Cust orders .csv'],\n\tskipDuplicateMapInputs: true,\n\tskipDuplicateMapOutputs: true,\n\tpartitionBy('hash', 1)) ~> UserQueryOutputDatasetCSVfiles"
										}
									]
								}
							]
						}
					}
				],
				"policy": {
					"elapsedTimeMetric": {}
				},
				"annotations": [],
				"lastPublishTime": "2024-06-29T02:56:33Z"
			},
			"dependsOn": [
				"[concat(variables('factoryId'), '/dataflows/Powerquery 2  - Merge Queries')]",
				"[concat(variables('factoryId'), '/datasets/OutputDatasetCSVfiles')]"
			]
		},
		{
			"name": "[concat(parameters('factoryName'), '/pipeline2 - SQL Database')]",
			"type": "Microsoft.DataFactory/factories/pipelines",
			"apiVersion": "2018-06-01",
			"properties": {
				"activities": [
					{
						"name": "Copy data1",
						"type": "Copy",
						"dependsOn": [],
						"policy": {
							"timeout": "0.12:00:00",
							"retry": 0,
							"retryIntervalInSeconds": 30,
							"secureOutput": false,
							"secureInput": false
						},
						"userProperties": [],
						"typeProperties": {
							"source": {
								"type": "SqlServerSource",
								"queryTimeout": "02:00:00",
								"partitionOption": "None"
							},
							"sink": {
								"type": "SqlServerSink",
								"writeBehavior": "insert",
								"sqlWriterUseTableLock": false
							},
							"enableStaging": false,
							"translator": {
								"type": "TabularTranslator",
								"typeConversion": true,
								"typeConversionSettings": {
									"allowDataTruncation": true,
									"treatBooleanAsNumber": false
								}
							}
						},
						"inputs": [
							{
								"referenceName": "Dataset_SqlTable",
								"type": "DatasetReference",
								"parameters": {
									"DBNamefromDataset": {
										"value": "@pipeline().parameters.SourceTable",
										"type": "Expression"
									},
									"TableName": {
										"value": "@pipeline().parameters.DbNamefromPipeline",
										"type": "Expression"
									}
								}
							}
						],
						"outputs": [
							{
								"referenceName": "Dataset_SqlTable",
								"type": "DatasetReference",
								"parameters": {
									"DBNamefromDataset": {
										"value": "@pipeline().parameters.DestinationTable",
										"type": "Expression"
									},
									"TableName": {
										"value": "@pipeline().parameters.DbNamefromPipeline",
										"type": "Expression"
									}
								}
							}
						]
					}
				],
				"policy": {
					"elapsedTimeMetric": {}
				},
				"parameters": {
					"SourceTable": {
						"type": "string"
					},
					"DbNamefromPipeline": {
						"type": "string"
					},
					"DestinationTable": {
						"type": "string"
					}
				},
				"annotations": [],
				"lastPublishTime": "2024-06-15T02:37:16Z"
			},
			"dependsOn": [
				"[concat(variables('factoryId'), '/datasets/Dataset_SqlTable')]"
			]
		},
		{
			"name": "[concat(parameters('factoryName'), '/pipeline2')]",
			"type": "Microsoft.DataFactory/factories/pipelines",
			"apiVersion": "2018-06-01",
			"properties": {
				"activities": [
					{
						"name": "Wait1",
						"type": "Wait",
						"dependsOn": [],
						"userProperties": [],
						"typeProperties": {
							"waitTimeInSeconds": 1
						}
					}
				],
				"policy": {
					"elapsedTimeMetric": {}
				},
				"annotations": []
			},
			"dependsOn": []
		},
		{
			"name": "[concat(parameters('factoryName'), '/pipeline3 - Copying CSV File MAPING')]",
			"type": "Microsoft.DataFactory/factories/pipelines",
			"apiVersion": "2018-06-01",
			"properties": {
				"activities": [
					{
						"name": "Copy data1",
						"description": "Mapping the tabular data in csv file in the sourcedataset and copying the mapped file to the DestinationDataset",
						"type": "Copy",
						"dependsOn": [],
						"policy": {
							"timeout": "0.12:00:00",
							"retry": 0,
							"retryIntervalInSeconds": 30,
							"secureOutput": false,
							"secureInput": false
						},
						"userProperties": [
							{
								"name": "Source",
								"value": "adfdemo/input/EmpSourceData.txt"
							},
							{
								"name": "Destination",
								"value": "adfdemo/output/"
							}
						],
						"typeProperties": {
							"source": {
								"type": "DelimitedTextSource",
								"storeSettings": {
									"type": "AzureBlobStorageReadSettings",
									"recursive": true,
									"enablePartitionDiscovery": false
								},
								"formatSettings": {
									"type": "DelimitedTextReadSettings"
								}
							},
							"sink": {
								"type": "DelimitedTextSink",
								"storeSettings": {
									"type": "AzureBlobStorageWriteSettings"
								},
								"formatSettings": {
									"type": "DelimitedTextWriteSettings",
									"quoteAllText": true,
									"fileExtension": ".txt"
								}
							},
							"enableStaging": false,
							"translator": {
								"type": "TabularTranslator",
								"mappings": [
									{
										"source": {
											"name": " Male",
											"type": "String",
											"physicalType": "String"
										},
										"sink": {
											"name": " Male",
											"type": "String",
											"physicalType": "String"
										}
									},
									{
										"source": {
											"name": "Seetharam",
											"type": "String",
											"physicalType": "String"
										},
										"sink": {
											"name": "Seetharam",
											"type": "String",
											"physicalType": "String"
										}
									},
									{
										"source": {
											"name": " 123",
											"type": "String",
											"physicalType": "String"
										},
										"sink": {
											"name": " 123",
											"type": "String",
											"physicalType": "String"
										}
									}
								],
								"typeConversion": true,
								"typeConversionSettings": {
									"allowDataTruncation": true,
									"treatBooleanAsNumber": false
								}
							}
						},
						"inputs": [
							{
								"referenceName": "Sourcedataset",
								"type": "DatasetReference",
								"parameters": {}
							}
						],
						"outputs": [
							{
								"referenceName": "DestinationDataset",
								"type": "DatasetReference",
								"parameters": {}
							}
						]
					}
				],
				"policy": {
					"elapsedTimeMetric": {}
				},
				"annotations": [],
				"lastPublishTime": "2024-06-16T05:43:15Z"
			},
			"dependsOn": [
				"[concat(variables('factoryId'), '/datasets/Sourcedataset')]",
				"[concat(variables('factoryId'), '/datasets/DestinationDataset')]"
			]
		},
		{
			"name": "[concat(parameters('factoryName'), '/pipeline3')]",
			"type": "Microsoft.DataFactory/factories/pipelines",
			"apiVersion": "2018-06-01",
			"properties": {
				"activities": [
					{
						"name": "Wait1",
						"type": "Wait",
						"dependsOn": [],
						"userProperties": [],
						"typeProperties": {
							"waitTimeInSeconds": 1
						}
					}
				],
				"policy": {
					"elapsedTimeMetric": {}
				},
				"annotations": []
			},
			"dependsOn": []
		},
		{
			"name": "[concat(parameters('factoryName'), '/pipeline4 - Delecting File')]",
			"type": "Microsoft.DataFactory/factories/pipelines",
			"apiVersion": "2018-06-01",
			"properties": {
				"activities": [
					{
						"name": "Delete1",
						"description": "Delecting all the txt files in the output folder in the adfdemo container using delete activity ",
						"type": "Delete",
						"dependsOn": [],
						"policy": {
							"timeout": "0.12:00:00",
							"retry": 0,
							"retryIntervalInSeconds": 30,
							"secureOutput": false,
							"secureInput": false
						},
						"userProperties": [
							{
								"name": "FilesDaleted",
								"value": "All TXT Files In Output folder of Adefdemo container"
							}
						],
						"typeProperties": {
							"dataset": {
								"referenceName": "OutputFolderDataset",
								"type": "DatasetReference",
								"parameters": {}
							},
							"logStorageSettings": {
								"linkedServiceName": {
									"referenceName": "Linkedservice_storagedemoramm",
									"type": "LinkedServiceReference"
								},
								"path": "adfdemo/output"
							},
							"enableLogging": true,
							"storeSettings": {
								"type": "AzureBlobStorageReadSettings",
								"recursive": true,
								"enablePartitionDiscovery": false
							}
						}
					}
				],
				"policy": {
					"elapsedTimeMetric": {}
				},
				"annotations": [],
				"lastPublishTime": "2024-06-16T05:43:15Z"
			},
			"dependsOn": [
				"[concat(variables('factoryId'), '/datasets/OutputFolderDataset')]",
				"[concat(variables('factoryId'), '/linkedServices/Linkedservice_storagedemoramm')]"
			]
		},
		{
			"name": "[concat(parameters('factoryName'), '/pipeline6 - Foreach CopyData')]",
			"type": "Microsoft.DataFactory/factories/pipelines",
			"apiVersion": "2018-06-01",
			"properties": {
				"activities": [
					{
						"name": "ForEach1",
						"description": "Copying The Data.txt file into 3 different folders with the 3 different file names in the same container ",
						"type": "ForEach",
						"dependsOn": [],
						"userProperties": [],
						"typeProperties": {
							"items": {
								"value": "@pipeline().parameters.OutputFolders",
								"type": "Expression"
							},
							"isSequential": true,
							"activities": [
								{
									"name": "Copy data1",
									"description": "Copying The Data.txt file into 3 different folders with the 3 different file names ",
									"type": "Copy",
									"dependsOn": [],
									"policy": {
										"timeout": "0.12:00:00",
										"retry": 0,
										"retryIntervalInSeconds": 30,
										"secureOutput": false,
										"secureInput": false
									},
									"userProperties": [
										{
											"name": "Source",
											"value": "adfdemo/input/data.txt"
										},
										{
											"name": "Destination",
											"value": "adfdemo/@{item()}/"
										}
									],
									"typeProperties": {
										"source": {
											"type": "BinarySource",
											"storeSettings": {
												"type": "AzureBlobStorageReadSettings",
												"recursive": true
											},
											"formatSettings": {
												"type": "BinaryReadSettings"
											}
										},
										"sink": {
											"type": "BinarySink",
											"storeSettings": {
												"type": "AzureBlobStorageWriteSettings"
											}
										},
										"enableStaging": false
									},
									"inputs": [
										{
											"referenceName": "InputDataDataSet",
											"type": "DatasetReference",
											"parameters": {}
										}
									],
									"outputs": [
										{
											"referenceName": "DemoramOutput",
											"type": "DatasetReference",
											"parameters": {
												"FolderName": {
													"value": "@item()",
													"type": "Expression"
												}
											}
										}
									]
								}
							]
						}
					}
				],
				"policy": {
					"elapsedTimeMetric": {}
				},
				"parameters": {
					"OutputFolders": {
						"type": "array",
						"defaultValue": [
							"output1/Data1.txt",
							"output2/Data2.txt",
							"output3/data3.txt"
						]
					}
				},
				"annotations": [],
				"lastPublishTime": "2024-06-16T02:27:02Z"
			},
			"dependsOn": [
				"[concat(variables('factoryId'), '/datasets/InputDataDataSet')]",
				"[concat(variables('factoryId'), '/datasets/DemoramOutput')]"
			]
		},
		{
			"name": "[concat(parameters('factoryName'), '/pipeline7 ForEach Deleting - pipline6')]",
			"type": "Microsoft.DataFactory/factories/pipelines",
			"apiVersion": "2018-06-01",
			"properties": {
				"activities": [
					{
						"name": "ForEachDeleting",
						"description": "Deleting the Folders copied / created in pipeline6 using Foreach",
						"type": "ForEach",
						"dependsOn": [],
						"userProperties": [],
						"typeProperties": {
							"items": {
								"value": "@pipeline().parameters.OutputFoldernames",
								"type": "Expression"
							},
							"isSequential": true,
							"activities": [
								{
									"name": "Delete1",
									"type": "Delete",
									"dependsOn": [],
									"policy": {
										"timeout": "0.12:00:00",
										"retry": 0,
										"retryIntervalInSeconds": 30,
										"secureOutput": false,
										"secureInput": false
									},
									"userProperties": [],
									"typeProperties": {
										"dataset": {
											"referenceName": "DemoramOutput",
											"type": "DatasetReference",
											"parameters": {
												"FolderName": {
													"value": "@item()",
													"type": "Expression"
												}
											}
										},
										"logStorageSettings": {
											"linkedServiceName": {
												"referenceName": "Linkedservice_storagedemoramm",
												"type": "LinkedServiceReference"
											},
											"path": {
												"value": "@item()",
												"type": "Expression"
											}
										},
										"enableLogging": true,
										"storeSettings": {
											"type": "AzureBlobStorageReadSettings",
											"recursive": true,
											"enablePartitionDiscovery": false
										}
									}
								}
							]
						}
					}
				],
				"policy": {
					"elapsedTimeMetric": {}
				},
				"parameters": {
					"OutputFoldernames": {
						"type": "array",
						"defaultValue": [
							"output1/Data1.txt",
							"output2/Data2.txt",
							"output3/data3.txt"
						]
					}
				},
				"annotations": [],
				"lastPublishTime": "2024-06-16T02:22:29Z"
			},
			"dependsOn": [
				"[concat(variables('factoryId'), '/datasets/DemoramOutput')]",
				"[concat(variables('factoryId'), '/linkedServices/Linkedservice_storagedemoramm')]"
			]
		},
		{
			"name": "[concat(parameters('factoryName'), '/pipeline8 IF Condition1')]",
			"type": "Microsoft.DataFactory/factories/pipelines",
			"apiVersion": "2018-06-01",
			"properties": {
				"activities": [
					{
						"name": "If Condition1",
						"type": "IfCondition",
						"dependsOn": [],
						"userProperties": [],
						"typeProperties": {
							"expression": {
								"value": "@bool(pipeline().parameters.Copytooutput1)",
								"type": "Expression"
							},
							"ifFalseActivities": [
								{
									"name": "Copy data2",
									"type": "Copy",
									"dependsOn": [],
									"policy": {
										"timeout": "0.12:00:00",
										"retry": 0,
										"retryIntervalInSeconds": 30,
										"secureOutput": false,
										"secureInput": false
									},
									"userProperties": [],
									"typeProperties": {
										"source": {
											"type": "BinarySource",
											"storeSettings": {
												"type": "AzureBlobStorageReadSettings",
												"recursive": true
											},
											"formatSettings": {
												"type": "BinaryReadSettings"
											}
										},
										"sink": {
											"type": "BinarySink",
											"storeSettings": {
												"type": "AzureBlobStorageWriteSettings"
											}
										},
										"enableStaging": false
									},
									"inputs": [
										{
											"referenceName": "InputDataDataSet",
											"type": "DatasetReference",
											"parameters": {}
										}
									],
									"outputs": [
										{
											"referenceName": "OutputLocationDataset",
											"type": "DatasetReference",
											"parameters": {
												"OutputFolder": {
													"value": "@pipeline().parameters.Output2Folder",
													"type": "Expression"
												}
											}
										}
									]
								}
							],
							"ifTrueActivities": [
								{
									"name": "Copy data1",
									"type": "Copy",
									"dependsOn": [],
									"policy": {
										"timeout": "0.12:00:00",
										"retry": 0,
										"retryIntervalInSeconds": 30,
										"secureOutput": false,
										"secureInput": false
									},
									"userProperties": [],
									"typeProperties": {
										"source": {
											"type": "BinarySource",
											"storeSettings": {
												"type": "AzureBlobStorageReadSettings",
												"recursive": true
											},
											"formatSettings": {
												"type": "BinaryReadSettings"
											}
										},
										"sink": {
											"type": "BinarySink",
											"storeSettings": {
												"type": "AzureBlobStorageWriteSettings"
											}
										},
										"enableStaging": false
									},
									"inputs": [
										{
											"referenceName": "InputDataDataSet",
											"type": "DatasetReference",
											"parameters": {}
										}
									],
									"outputs": [
										{
											"referenceName": "OutputLocationDataset",
											"type": "DatasetReference",
											"parameters": {
												"OutputFolder": {
													"value": "@pipeline().parameters.Output1Folder",
													"type": "Expression"
												}
											}
										}
									]
								}
							]
						}
					}
				],
				"policy": {
					"elapsedTimeMetric": {}
				},
				"parameters": {
					"Copytooutput1": {
						"type": "string",
						"defaultValue": "true"
					},
					"Output1Folder": {
						"type": "string",
						"defaultValue": "Output1"
					},
					"Output2Folder": {
						"type": "string",
						"defaultValue": "Output2"
					}
				},
				"annotations": [],
				"lastPublishTime": "2024-06-16T05:07:28Z"
			},
			"dependsOn": [
				"[concat(variables('factoryId'), '/datasets/InputDataDataSet')]",
				"[concat(variables('factoryId'), '/datasets/OutputLocationDataset')]"
			]
		},
		{
			"name": "[concat(parameters('factoryName'), '/pipeline9 - Wait Activity')]",
			"type": "Microsoft.DataFactory/factories/pipelines",
			"apiVersion": "2018-06-01",
			"properties": {
				"description": "Wait Activity to exquisite the pipeline after the time mentioned directly or through the parameter dynamic Content ",
				"activities": [
					{
						"name": "Wait1",
						"description": "This activity introduces a delay in the pipeline execution for a specified duration. It is used to ensure that subsequent activities, such as the 'Execute Pipeline' activity, do not start immediately. This can be useful in scenarios where there is a need to wait for external processes to complete or to stagger the execution of dependent pipelines.",
						"type": "Wait",
						"dependsOn": [],
						"userProperties": [],
						"typeProperties": {
							"waitTimeInSeconds": {
								"value": "@pipeline().parameters.waitfors10ecs",
								"type": "Expression"
							}
						}
					},
					{
						"name": "Execute Pipeline 1 using wait activity",
						"type": "ExecutePipeline",
						"dependsOn": [
							{
								"activity": "Wait1",
								"dependencyConditions": [
									"Succeeded"
								]
							}
						],
						"policy": {
							"secureInput": false
						},
						"userProperties": [],
						"typeProperties": {
							"pipeline": {
								"referenceName": "pipeline1 - copying TXT File",
								"type": "PipelineReference"
							},
							"waitOnCompletion": true,
							"parameters": {}
						}
					}
				],
				"policy": {
					"elapsedTimeMetric": {}
				},
				"parameters": {
					"waitfors10ecs": {
						"type": "int",
						"defaultValue": 10
					}
				},
				"annotations": [],
				"lastPublishTime": "2024-06-16T05:43:15Z"
			},
			"dependsOn": [
				"[concat(variables('factoryId'), '/pipelines/pipeline1 - copying TXT File')]"
			]
		},
		{
			"name": "[concat(parameters('factoryName'), '/CustomersDataset')]",
			"type": "Microsoft.DataFactory/factories/datasets",
			"apiVersion": "2018-06-01",
			"properties": {
				"linkedServiceName": {
					"referenceName": "Linkedservice_storagedemoramm",
					"type": "LinkedServiceReference"
				},
				"annotations": [],
				"type": "DelimitedText",
				"typeProperties": {
					"location": {
						"type": "AzureBlobStorageLocation",
						"fileName": "Customers.csv",
						"folderPath": "input",
						"container": "adfdemo"
					},
					"columnDelimiter": ",",
					"escapeChar": "\\",
					"firstRowAsHeader": true,
					"quoteChar": "\""
				},
				"schema": [
					{
						"name": "CustomerID",
						"type": "String"
					},
					{
						"name": "CustomerName",
						"type": "String"
					},
					{
						"name": "ContactName",
						"type": "String"
					},
					{
						"name": "Address",
						"type": "String"
					},
					{
						"name": "City",
						"type": "String"
					},
					{
						"name": "PostalCode",
						"type": "String"
					},
					{
						"name": "Country",
						"type": "String"
					}
				]
			},
			"dependsOn": [
				"[concat(variables('factoryId'), '/linkedServices/Linkedservice_storagedemoramm')]"
			]
		},
		{
			"name": "[concat(parameters('factoryName'), '/Dataset_SqlTable')]",
			"type": "Microsoft.DataFactory/factories/datasets",
			"apiVersion": "2018-06-01",
			"properties": {
				"linkedServiceName": {
					"referenceName": "LinkedService_Sql",
					"type": "LinkedServiceReference"
				},
				"parameters": {
					"DBNamefromDataset": {
						"type": "string"
					},
					"TableName": {
						"type": "string"
					}
				},
				"annotations": [],
				"type": "SqlServerTable",
				"schema": [],
				"typeProperties": {
					"schema": {
						"value": "@dataset().TableName",
						"type": "Expression"
					},
					"table": {
						"value": "@dataset().TableName",
						"type": "Expression"
					}
				}
			},
			"dependsOn": [
				"[concat(variables('factoryId'), '/linkedServices/LinkedService_Sql')]"
			]
		},
		{
			"name": "[concat(parameters('factoryName'), '/DemoramOutput')]",
			"type": "Microsoft.DataFactory/factories/datasets",
			"apiVersion": "2018-06-01",
			"properties": {
				"linkedServiceName": {
					"referenceName": "Linkedservice_storagedemoramm",
					"type": "LinkedServiceReference"
				},
				"parameters": {
					"FolderName": {
						"type": "string"
					}
				},
				"annotations": [],
				"type": "Binary",
				"typeProperties": {
					"location": {
						"type": "AzureBlobStorageLocation",
						"folderPath": {
							"value": "@dataset().FolderName",
							"type": "Expression"
						},
						"container": "adfdemo"
					}
				}
			},
			"dependsOn": [
				"[concat(variables('factoryId'), '/linkedServices/Linkedservice_storagedemoramm')]"
			]
		},
		{
			"name": "[concat(parameters('factoryName'), '/DestinationDataset')]",
			"type": "Microsoft.DataFactory/factories/datasets",
			"apiVersion": "2018-06-01",
			"properties": {
				"linkedServiceName": {
					"referenceName": "Linkedservice_storagedemoramm",
					"type": "LinkedServiceReference"
				},
				"annotations": [],
				"type": "DelimitedText",
				"typeProperties": {
					"location": {
						"type": "AzureBlobStorageLocation",
						"folderPath": "output",
						"container": "adfdemo"
					},
					"columnDelimiter": ",",
					"escapeChar": "\\",
					"firstRowAsHeader": true,
					"quoteChar": "\""
				},
				"schema": []
			},
			"dependsOn": [
				"[concat(variables('factoryId'), '/linkedServices/Linkedservice_storagedemoramm')]"
			]
		},
		{
			"name": "[concat(parameters('factoryName'), '/EmpMaheerDataDataset')]",
			"type": "Microsoft.DataFactory/factories/datasets",
			"apiVersion": "2018-06-01",
			"properties": {
				"linkedServiceName": {
					"referenceName": "Linkedservice_storagedemoramm",
					"type": "LinkedServiceReference"
				},
				"annotations": [],
				"type": "DelimitedText",
				"typeProperties": {
					"location": {
						"type": "AzureBlobStorageLocation",
						"fileName": "EmployeeMaheerData.csv",
						"folderPath": "input",
						"container": "adfdemo"
					},
					"columnDelimiter": ",",
					"escapeChar": "\\",
					"firstRowAsHeader": true,
					"quoteChar": "\""
				},
				"schema": [
					{
						"name": "id",
						"type": "String"
					},
					{
						"name": "name",
						"type": "String"
					},
					{
						"name": "gender",
						"type": "String"
					},
					{
						"name": "country",
						"type": "String"
					},
					{
						"name": "salary",
						"type": "String"
					},
					{
						"name": "department",
						"type": "String"
					}
				]
			},
			"dependsOn": [
				"[concat(variables('factoryId'), '/linkedServices/Linkedservice_storagedemoramm')]"
			]
		},
		{
			"name": "[concat(parameters('factoryName'), '/EmployeeDataset')]",
			"type": "Microsoft.DataFactory/factories/datasets",
			"apiVersion": "2018-06-01",
			"properties": {
				"linkedServiceName": {
					"referenceName": "Linkedservice_storagedemoramm",
					"type": "LinkedServiceReference"
				},
				"annotations": [],
				"type": "DelimitedText",
				"typeProperties": {
					"location": {
						"type": "AzureBlobStorageLocation",
						"fileName": "Employee.csv",
						"folderPath": "input",
						"container": "adfdemo"
					},
					"columnDelimiter": ",",
					"escapeChar": "\\",
					"firstRowAsHeader": true,
					"quoteChar": "\""
				},
				"schema": [
					{
						"name": "EmployeeID",
						"type": "String"
					},
					{
						"name": "LastName",
						"type": "String"
					},
					{
						"name": "FirstName",
						"type": "String"
					},
					{
						"name": "BirthDate",
						"type": "String"
					},
					{
						"name": "Photo",
						"type": "String"
					},
					{
						"name": "Notes",
						"type": "String"
					}
				]
			},
			"dependsOn": [
				"[concat(variables('factoryId'), '/linkedServices/Linkedservice_storagedemoramm')]"
			]
		},
		{
			"name": "[concat(parameters('factoryName'), '/InputDataDataSet')]",
			"type": "Microsoft.DataFactory/factories/datasets",
			"apiVersion": "2018-06-01",
			"properties": {
				"linkedServiceName": {
					"referenceName": "Linkedservice_storagedemoramm",
					"type": "LinkedServiceReference"
				},
				"annotations": [],
				"type": "Binary",
				"typeProperties": {
					"location": {
						"type": "AzureBlobStorageLocation",
						"fileName": "data.txt",
						"folderPath": "input",
						"container": "adfdemo"
					}
				}
			},
			"dependsOn": [
				"[concat(variables('factoryId'), '/linkedServices/Linkedservice_storagedemoramm')]"
			]
		},
		{
			"name": "[concat(parameters('factoryName'), '/InputDataDatasetCSV')]",
			"type": "Microsoft.DataFactory/factories/datasets",
			"apiVersion": "2018-06-01",
			"properties": {
				"linkedServiceName": {
					"referenceName": "Linkedservice_storagedemoramm",
					"type": "LinkedServiceReference"
				},
				"annotations": [],
				"type": "DelimitedText",
				"typeProperties": {
					"location": {
						"type": "AzureBlobStorageLocation",
						"folderPath": "input",
						"container": "adfdemo"
					},
					"columnDelimiter": ",",
					"escapeChar": "\\",
					"firstRowAsHeader": true,
					"quoteChar": "\""
				},
				"schema": []
			},
			"dependsOn": [
				"[concat(variables('factoryId'), '/linkedServices/Linkedservice_storagedemoramm')]"
			]
		},
		{
			"name": "[concat(parameters('factoryName'), '/OrdersDataset')]",
			"type": "Microsoft.DataFactory/factories/datasets",
			"apiVersion": "2018-06-01",
			"properties": {
				"linkedServiceName": {
					"referenceName": "Linkedservice_storagedemoramm",
					"type": "LinkedServiceReference"
				},
				"annotations": [],
				"type": "DelimitedText",
				"typeProperties": {
					"location": {
						"type": "AzureBlobStorageLocation",
						"fileName": "Orders.csv",
						"folderPath": "input",
						"container": "adfdemo"
					},
					"columnDelimiter": ",",
					"escapeChar": "\\",
					"firstRowAsHeader": true,
					"quoteChar": "\""
				},
				"schema": [
					{
						"name": "OrderID",
						"type": "String"
					},
					{
						"name": "CustomerID",
						"type": "String"
					},
					{
						"name": "EmployeeID",
						"type": "String"
					},
					{
						"name": "OrderDate",
						"type": "String"
					},
					{
						"name": "ShipperID",
						"type": "String"
					}
				]
			},
			"dependsOn": [
				"[concat(variables('factoryId'), '/linkedServices/Linkedservice_storagedemoramm')]"
			]
		},
		{
			"name": "[concat(parameters('factoryName'), '/OutputDataDataset')]",
			"type": "Microsoft.DataFactory/factories/datasets",
			"apiVersion": "2018-06-01",
			"properties": {
				"linkedServiceName": {
					"referenceName": "Linkedservice_storagedemoramm",
					"type": "LinkedServiceReference"
				},
				"annotations": [],
				"type": "Binary",
				"typeProperties": {
					"location": {
						"type": "AzureBlobStorageLocation",
						"fileName": "data.txt",
						"folderPath": "output",
						"container": "adfdemo"
					}
				}
			},
			"dependsOn": [
				"[concat(variables('factoryId'), '/linkedServices/Linkedservice_storagedemoramm')]"
			]
		},
		{
			"name": "[concat(parameters('factoryName'), '/OutputDatasetCSVfiles')]",
			"type": "Microsoft.DataFactory/factories/datasets",
			"apiVersion": "2018-06-01",
			"properties": {
				"linkedServiceName": {
					"referenceName": "Linkedservice_storagedemoramm",
					"type": "LinkedServiceReference"
				},
				"annotations": [],
				"type": "DelimitedText",
				"typeProperties": {
					"location": {
						"type": "AzureBlobStorageLocation",
						"folderPath": "output",
						"container": "adfdemo"
					},
					"columnDelimiter": ",",
					"escapeChar": "\\",
					"firstRowAsHeader": true,
					"quoteChar": "\""
				},
				"schema": []
			},
			"dependsOn": [
				"[concat(variables('factoryId'), '/linkedServices/Linkedservice_storagedemoramm')]"
			]
		},
		{
			"name": "[concat(parameters('factoryName'), '/OutputFolderDataset')]",
			"type": "Microsoft.DataFactory/factories/datasets",
			"apiVersion": "2018-06-01",
			"properties": {
				"linkedServiceName": {
					"referenceName": "Linkedservice_storagedemoramm",
					"type": "LinkedServiceReference"
				},
				"annotations": [],
				"type": "Binary",
				"typeProperties": {
					"location": {
						"type": "AzureBlobStorageLocation",
						"folderPath": "output",
						"container": "adfdemo"
					}
				}
			},
			"dependsOn": [
				"[concat(variables('factoryId'), '/linkedServices/Linkedservice_storagedemoramm')]"
			]
		},
		{
			"name": "[concat(parameters('factoryName'), '/OutputLocationDataset')]",
			"type": "Microsoft.DataFactory/factories/datasets",
			"apiVersion": "2018-06-01",
			"properties": {
				"linkedServiceName": {
					"referenceName": "Linkedservice_storagedemoramm",
					"type": "LinkedServiceReference"
				},
				"parameters": {
					"OutputFolder": {
						"type": "string"
					}
				},
				"annotations": [],
				"type": "Binary",
				"typeProperties": {
					"location": {
						"type": "AzureBlobStorageLocation",
						"folderPath": {
							"value": "@dataset().OutputFolder",
							"type": "Expression"
						},
						"container": "adfdemo"
					}
				}
			},
			"dependsOn": [
				"[concat(variables('factoryId'), '/linkedServices/Linkedservice_storagedemoramm')]"
			]
		},
		{
			"name": "[concat(parameters('factoryName'), '/PivortedShipperAndEmpfile')]",
			"type": "Microsoft.DataFactory/factories/datasets",
			"apiVersion": "2018-06-01",
			"properties": {
				"linkedServiceName": {
					"referenceName": "Linkedservice_storagedemoramm",
					"type": "LinkedServiceReference"
				},
				"annotations": [],
				"type": "DelimitedText",
				"typeProperties": {
					"location": {
						"type": "AzureBlobStorageLocation",
						"fileName": "Pivot shipper and emp id (agrate).csv",
						"folderPath": "output",
						"container": "adfdemo"
					},
					"columnDelimiter": ",",
					"escapeChar": "\\",
					"firstRowAsHeader": true,
					"quoteChar": "\""
				},
				"schema": [
					{
						"name": "ShipperID",
						"type": "String"
					},
					{
						"name": "Emp ID:1",
						"type": "String"
					},
					{
						"name": "Emp ID:2",
						"type": "String"
					},
					{
						"name": "Emp ID:3",
						"type": "String"
					},
					{
						"name": "Emp ID:4",
						"type": "String"
					},
					{
						"name": "Emp ID:5",
						"type": "String"
					},
					{
						"name": "Emp ID:6",
						"type": "String"
					},
					{
						"name": "Emp ID:7",
						"type": "String"
					},
					{
						"name": "Emp ID:8",
						"type": "String"
					},
					{
						"name": "Emp ID:9",
						"type": "String"
					}
				]
			},
			"dependsOn": [
				"[concat(variables('factoryId'), '/linkedServices/Linkedservice_storagedemoramm')]"
			]
		},
		{
			"name": "[concat(parameters('factoryName'), '/ProductsDataset')]",
			"type": "Microsoft.DataFactory/factories/datasets",
			"apiVersion": "2018-06-01",
			"properties": {
				"linkedServiceName": {
					"referenceName": "Linkedservice_storagedemoramm",
					"type": "LinkedServiceReference"
				},
				"annotations": [],
				"type": "DelimitedText",
				"typeProperties": {
					"location": {
						"type": "AzureBlobStorageLocation",
						"fileName": "Products.csv",
						"folderPath": "input",
						"container": "adfdemo"
					},
					"columnDelimiter": ",",
					"escapeChar": "\\",
					"firstRowAsHeader": true,
					"quoteChar": "\""
				},
				"schema": [
					{
						"name": "ProductID",
						"type": "String"
					},
					{
						"name": "ProductName",
						"type": "String"
					},
					{
						"name": "SupplierID",
						"type": "String"
					},
					{
						"name": "CategoryID",
						"type": "String"
					},
					{
						"name": "Unit",
						"type": "String"
					},
					{
						"name": "Price",
						"type": "String"
					}
				]
			},
			"dependsOn": [
				"[concat(variables('factoryId'), '/linkedServices/Linkedservice_storagedemoramm')]"
			]
		},
		{
			"name": "[concat(parameters('factoryName'), '/Shiper1Dataset')]",
			"type": "Microsoft.DataFactory/factories/datasets",
			"apiVersion": "2018-06-01",
			"properties": {
				"linkedServiceName": {
					"referenceName": "Linkedservice_storagedemoramm",
					"type": "LinkedServiceReference"
				},
				"annotations": [],
				"type": "DelimitedText",
				"typeProperties": {
					"location": {
						"type": "AzureBlobStorageLocation",
						"fileName": "Shipper1.csv",
						"folderPath": "input",
						"container": "adfdemo"
					},
					"columnDelimiter": ",",
					"escapeChar": "\\",
					"firstRowAsHeader": true,
					"quoteChar": "\""
				},
				"schema": []
			},
			"dependsOn": [
				"[concat(variables('factoryId'), '/linkedServices/Linkedservice_storagedemoramm')]"
			]
		},
		{
			"name": "[concat(parameters('factoryName'), '/Shipper2Dataset')]",
			"type": "Microsoft.DataFactory/factories/datasets",
			"apiVersion": "2018-06-01",
			"properties": {
				"linkedServiceName": {
					"referenceName": "Linkedservice_storagedemoramm",
					"type": "LinkedServiceReference"
				},
				"annotations": [],
				"type": "DelimitedText",
				"typeProperties": {
					"location": {
						"type": "AzureBlobStorageLocation",
						"fileName": "Shipper2.csv",
						"folderPath": "input",
						"container": "adfdemo"
					},
					"columnDelimiter": ",",
					"escapeChar": "\\",
					"firstRowAsHeader": true,
					"quoteChar": "\""
				},
				"schema": []
			},
			"dependsOn": [
				"[concat(variables('factoryId'), '/linkedServices/Linkedservice_storagedemoramm')]"
			]
		},
		{
			"name": "[concat(parameters('factoryName'), '/ShipperDataset')]",
			"type": "Microsoft.DataFactory/factories/datasets",
			"apiVersion": "2018-06-01",
			"properties": {
				"linkedServiceName": {
					"referenceName": "Linkedservice_storagedemoramm",
					"type": "LinkedServiceReference"
				},
				"annotations": [],
				"type": "DelimitedText",
				"typeProperties": {
					"location": {
						"type": "AzureBlobStorageLocation",
						"fileName": "Shippers.csv",
						"folderPath": "input",
						"container": "adfdemo"
					},
					"columnDelimiter": ",",
					"escapeChar": "\\",
					"firstRowAsHeader": true,
					"quoteChar": "\""
				},
				"schema": [
					{
						"name": "ShipperID",
						"type": "String"
					},
					{
						"name": "ShipperName",
						"type": "String"
					},
					{
						"name": "Phone",
						"type": "String"
					}
				]
			},
			"dependsOn": [
				"[concat(variables('factoryId'), '/linkedServices/Linkedservice_storagedemoramm')]"
			]
		},
		{
			"name": "[concat(parameters('factoryName'), '/Sourcedataset')]",
			"type": "Microsoft.DataFactory/factories/datasets",
			"apiVersion": "2018-06-01",
			"properties": {
				"linkedServiceName": {
					"referenceName": "Linkedservice_storagedemoramm",
					"type": "LinkedServiceReference"
				},
				"annotations": [],
				"type": "DelimitedText",
				"typeProperties": {
					"location": {
						"type": "AzureBlobStorageLocation",
						"fileName": "EmpSourceData.txt",
						"folderPath": "input",
						"container": "adfdemo"
					},
					"columnDelimiter": ",",
					"escapeChar": "\\",
					"firstRowAsHeader": true,
					"quoteChar": "\""
				},
				"schema": [
					{
						"name": "Seetharam",
						"type": "String"
					},
					{
						"name": " Male",
						"type": "String"
					},
					{
						"name": " 123",
						"type": "String"
					}
				]
			},
			"dependsOn": [
				"[concat(variables('factoryId'), '/linkedServices/Linkedservice_storagedemoramm')]"
			]
		},
		{
			"name": "[concat(parameters('factoryName'), '/LinkedService_Sql')]",
			"type": "Microsoft.DataFactory/factories/linkedServices",
			"apiVersion": "2018-06-01",
			"properties": {
				"parameters": {
					"DbName": {
						"type": "string"
					}
				},
				"annotations": [],
				"type": "SqlServer",
				"typeProperties": {
					"server": "[parameters('LinkedService_Sql_properties_typeProperties_server')]",
					"database": "[parameters('LinkedService_Sql_properties_typeProperties_database')]",
					"encrypt": "mandatory",
					"trustServerCertificate": false,
					"authenticationType": "SQL",
					"userName": "[parameters('LinkedService_Sql_properties_typeProperties_userName')]",
					"password": {
						"type": "SecureString",
						"value": "[parameters('LinkedService_Sql_password')]"
					}
				}
			},
			"dependsOn": []
		},
		{
			"name": "[concat(parameters('factoryName'), '/Linkedservice_storagedemoramm')]",
			"type": "Microsoft.DataFactory/factories/linkedServices",
			"apiVersion": "2018-06-01",
			"properties": {
				"annotations": [],
				"type": "AzureBlobStorage",
				"typeProperties": {
					"connectionString": "[parameters('Linkedservice_storagedemoramm_connectionString')]"
				}
			},
			"dependsOn": []
		},
		{
			"name": "[concat(parameters('factoryName'), '/trigger1')]",
			"type": "Microsoft.DataFactory/factories/triggers",
			"apiVersion": "2018-06-01",
			"properties": {
				"annotations": [],
				"runtimeState": "Started",
				"pipelines": [
					{
						"pipelineReference": {
							"referenceName": "pipeline2 - SQL Database",
							"type": "PipelineReference"
						},
						"parameters": {
							"SourceTable": "[parameters('trigger1_properties_pipeline2 - SQL Database_parameters_SourceTable')]",
							"DbNamefromPipeline": "[parameters('trigger1_properties_pipeline2 - SQL Database_parameters_DbNamefromPipeline')]",
							"DestinationTable": "[parameters('trigger1_properties_pipeline2 - SQL Database_parameters_DestinationTable')]"
						}
					}
				],
				"type": "ScheduleTrigger",
				"typeProperties": {
					"recurrence": {
						"frequency": "Month",
						"interval": 1,
						"startTime": "2024-06-14T00:22:00",
						"endTime": "2024-06-14T21:25:29",
						"timeZone": "GMT Standard Time",
						"schedule": {
							"monthDays": [
								-1
							]
						}
					}
				}
			},
			"dependsOn": [
				"[concat(variables('factoryId'), '/pipelines/pipeline2 - SQL Database')]"
			]
		},
		{
			"name": "[concat(parameters('factoryName'), '/IR-SelfHost')]",
			"type": "Microsoft.DataFactory/factories/integrationRuntimes",
			"apiVersion": "2018-06-01",
			"properties": {
				"type": "SelfHosted",
				"typeProperties": {}
			},
			"dependsOn": []
		},
		{
			"name": "[concat(parameters('factoryName'), '/AggregateTotalOrdersbyShipdataflow')]",
			"type": "Microsoft.DataFactory/factories/dataflows",
			"apiVersion": "2018-06-01",
			"properties": {
				"type": "MappingDataFlow",
				"typeProperties": {
					"sources": [
						{
							"dataset": {
								"referenceName": "OrdersDataset",
								"type": "DatasetReference"
							},
							"name": "Orders"
						},
						{
							"dataset": {
								"referenceName": "ShipperDataset",
								"type": "DatasetReference"
							},
							"name": "Shippers"
						}
					],
					"sinks": [
						{
							"dataset": {
								"referenceName": "OutputDatasetCSVfiles",
								"type": "DatasetReference"
							},
							"name": "sink1"
						}
					],
					"transformations": [
						{
							"name": "aggregate1"
						},
						{
							"name": "join1"
						}
					],
					"scriptLines": [
						"source(output(",
						"          OrderID as string,",
						"          CustomerID as string,",
						"          EmployeeID as string,",
						"          OrderDate as string,",
						"          ShipperID as string",
						"     ),",
						"     allowSchemaDrift: true,",
						"     validateSchema: false,",
						"     ignoreNoFilesFound: false) ~> Orders",
						"source(output(",
						"          ShipperID as string,",
						"          ShipperName as string,",
						"          Phone as string",
						"     ),",
						"     allowSchemaDrift: true,",
						"     validateSchema: false,",
						"     ignoreNoFilesFound: false) ~> Shippers",
						"Orders aggregate(groupBy(ShipperID),",
						"     TotalOrders = count(OrderID)) ~> aggregate1",
						"aggregate1, Shippers join(aggregate1@ShipperID == Shippers@ShipperID,",
						"     joinType:'inner',",
						"     matchType:'exact',",
						"     ignoreSpaces: false,",
						"     broadcast: 'auto')~> join1",
						"join1 sink(allowSchemaDrift: true,",
						"     validateSchema: false,",
						"     partitionFileNames:['Orders By Shippers.csv'],",
						"     skipDuplicateMapInputs: true,",
						"     skipDuplicateMapOutputs: true,",
						"     mapColumn(",
						"          ShipperID = aggregate1@ShipperID,",
						"          ShipperName,",
						"          TotalOrders",
						"     ),",
						"     partitionBy('hash', 1)) ~> sink1"
					]
				}
			},
			"dependsOn": [
				"[concat(variables('factoryId'), '/datasets/OrdersDataset')]",
				"[concat(variables('factoryId'), '/datasets/ShipperDataset')]",
				"[concat(variables('factoryId'), '/datasets/OutputDatasetCSVfiles')]"
			]
		},
		{
			"name": "[concat(parameters('factoryName'), '/AlterRowDataflow')]",
			"type": "Microsoft.DataFactory/factories/dataflows",
			"apiVersion": "2018-06-01",
			"properties": {
				"description": "Alter Row transformation used to insert, update, delete, and upset on rows based on the condition.\nexample: where clause with insert/delete statements in SQL ",
				"type": "MappingDataFlow",
				"typeProperties": {
					"sources": [
						{
							"dataset": {
								"referenceName": "EmpMaheerDataDataset",
								"type": "DatasetReference"
							},
							"name": "source1"
						}
					],
					"sinks": [
						{
							"dataset": {
								"referenceName": "EmpMaheerDataDataset",
								"type": "DatasetReference"
							},
							"name": "sink1"
						}
					],
					"transformations": [
						{
							"name": "alterRow1"
						}
					],
					"scriptLines": [
						"source(output(",
						"          id as integer,",
						"          name as string,",
						"          gender as string,",
						"          country as string,",
						"          salary as integer,",
						"          department as string",
						"     ),",
						"     allowSchemaDrift: true,",
						"     validateSchema: false,",
						"     ignoreNoFilesFound: false) ~> source1",
						"source1 alterRow(deleteIf(gender=='male'),",
						"     updateIf(department=='IT')) ~> alterRow1",
						"alterRow1 sink(allowSchemaDrift: true,",
						"     validateSchema: false,",
						"     input(",
						"          id as string,",
						"          name as string,",
						"          gender as string,",
						"          country as string,",
						"          salary as string,",
						"          department as string",
						"     ),",
						"     skipDuplicateMapInputs: true,",
						"     skipDuplicateMapOutputs: true) ~> sink1"
					]
				}
			},
			"dependsOn": [
				"[concat(variables('factoryId'), '/datasets/EmpMaheerDataDataset')]"
			]
		},
		{
			"name": "[concat(parameters('factoryName'), '/ConditionlSplitDataflow')]",
			"type": "Microsoft.DataFactory/factories/dataflows",
			"apiVersion": "2018-06-01",
			"properties": {
				"type": "MappingDataFlow",
				"typeProperties": {
					"sources": [
						{
							"dataset": {
								"referenceName": "OrdersDataset",
								"type": "DatasetReference"
							},
							"name": "source1"
						}
					],
					"sinks": [
						{
							"dataset": {
								"referenceName": "OutputDatasetCSVfiles",
								"type": "DatasetReference"
							},
							"name": "Ship1Sink"
						},
						{
							"dataset": {
								"referenceName": "OutputDatasetCSVfiles",
								"type": "DatasetReference"
							},
							"name": "Ship2Sink"
						},
						{
							"dataset": {
								"referenceName": "OutputDatasetCSVfiles",
								"type": "DatasetReference"
							},
							"name": "Ship3Sink"
						}
					],
					"transformations": [
						{
							"name": "splitbasedoncondition"
						}
					],
					"scriptLines": [
						"source(output(",
						"          OrderID as string,",
						"          CustomerID as string,",
						"          EmployeeID as string,",
						"          OrderDate as string,",
						"          ShipperID as string",
						"     ),",
						"     allowSchemaDrift: true,",
						"     validateSchema: false,",
						"     ignoreNoFilesFound: false) ~> source1",
						"source1 split(equals(ShipperID, '1'),",
						"     equals(ShipperID, '2'),",
						"     equals(ShipperID, '3'),",
						"     disjoint: false) ~> splitbasedoncondition@(Ship1SpeedyExpress, Ship2UnitedPackage, Ship3FederalShipping)",
						"splitbasedoncondition@Ship1SpeedyExpress sink(allowSchemaDrift: true,",
						"     validateSchema: false,",
						"     partitionFileNames:['Shipper1.csv'],",
						"     skipDuplicateMapInputs: true,",
						"     skipDuplicateMapOutputs: true,",
						"     partitionBy('hash', 1)) ~> Ship1Sink",
						"splitbasedoncondition@Ship2UnitedPackage sink(allowSchemaDrift: true,",
						"     validateSchema: false,",
						"     partitionFileNames:['Shipper2.csv'],",
						"     skipDuplicateMapInputs: true,",
						"     skipDuplicateMapOutputs: true,",
						"     partitionBy('hash', 1)) ~> Ship2Sink",
						"splitbasedoncondition@Ship3FederalShipping sink(allowSchemaDrift: true,",
						"     validateSchema: false,",
						"     partitionFileNames:['Shipper3.csv'],",
						"     skipDuplicateMapInputs: true,",
						"     skipDuplicateMapOutputs: true,",
						"     partitionBy('hash', 1)) ~> Ship3Sink"
					]
				}
			},
			"dependsOn": [
				"[concat(variables('factoryId'), '/datasets/OrdersDataset')]",
				"[concat(variables('factoryId'), '/datasets/OutputDatasetCSVfiles')]"
			]
		},
		{
			"name": "[concat(parameters('factoryName'), '/DerivedColumndataflow')]",
			"type": "Microsoft.DataFactory/factories/dataflows",
			"apiVersion": "2018-06-01",
			"properties": {
				"description": "updating the country column to upper case and the postal code column null values to unknown (R37)",
				"type": "MappingDataFlow",
				"typeProperties": {
					"sources": [
						{
							"dataset": {
								"referenceName": "CustomersDataset",
								"type": "DatasetReference"
							},
							"name": "source1"
						}
					],
					"sinks": [
						{
							"dataset": {
								"referenceName": "OutputDatasetCSVfiles",
								"type": "DatasetReference"
							},
							"name": "sink1"
						}
					],
					"transformations": [
						{
							"name": "derivedColumn1",
							"description": "Creating/updating the columns 'CustomerID, CustomerName, ContactName, Address, City, PostalCode, Country'"
						}
					],
					"scriptLines": [
						"source(output(",
						"          CustomerID as string,",
						"          CustomerName as string,",
						"          ContactName as string,",
						"          Address as string,",
						"          City as string,",
						"          PostalCode as string,",
						"          Country as string",
						"     ),",
						"     allowSchemaDrift: true,",
						"     validateSchema: false,",
						"     ignoreNoFilesFound: false) ~> source1",
						"source1 derive(Country = upper(Country),",
						"          PostalCode = iif(isNull(PostalCode), 'Unknown', upper(PostalCode))) ~> derivedColumn1",
						"derivedColumn1 sink(allowSchemaDrift: true,",
						"     validateSchema: false,",
						"     partitionFileNames:['Customer New.csv'],",
						"     skipDuplicateMapInputs: true,",
						"     skipDuplicateMapOutputs: true,",
						"     partitionBy('hash', 1)) ~> sink1"
					]
				}
			},
			"dependsOn": [
				"[concat(variables('factoryId'), '/datasets/CustomersDataset')]",
				"[concat(variables('factoryId'), '/datasets/OutputDatasetCSVfiles')]"
			]
		},
		{
			"name": "[concat(parameters('factoryName'), '/Eistsdataflow')]",
			"type": "Microsoft.DataFactory/factories/dataflows",
			"apiVersion": "2018-06-01",
			"properties": {
				"description": "Using exits x",
				"type": "MappingDataFlow",
				"typeProperties": {
					"sources": [
						{
							"dataset": {
								"referenceName": "EmployeeDataset",
								"type": "DatasetReference"
							},
							"name": "Employee"
						},
						{
							"dataset": {
								"referenceName": "OrdersDataset",
								"type": "DatasetReference"
							},
							"name": "Orders"
						}
					],
					"sinks": [
						{
							"dataset": {
								"referenceName": "OutputDatasetCSVfiles",
								"type": "DatasetReference"
							},
							"name": "sink1",
							"rejectedDataLinkedService": {
								"referenceName": "Linkedservice_storagedemoramm",
								"type": "LinkedServiceReference"
							}
						}
					],
					"transformations": [
						{
							"name": "exists1"
						}
					],
					"scriptLines": [
						"source(output(",
						"          EmployeeID as string,",
						"          LastName as string,",
						"          FirstName as string,",
						"          BirthDate as string,",
						"          Photo as string,",
						"          Notes as string",
						"     ),",
						"     allowSchemaDrift: true,",
						"     validateSchema: false,",
						"     ignoreNoFilesFound: false) ~> Employee",
						"source(output(",
						"          OrderID as string,",
						"          CustomerID as string,",
						"          EmployeeID as string,",
						"          OrderDate as string,",
						"          ShipperID as string",
						"     ),",
						"     allowSchemaDrift: true,",
						"     validateSchema: false,",
						"     ignoreNoFilesFound: false) ~> Orders",
						"Employee, Orders exists(Employee@EmployeeID == Orders@EmployeeID,",
						"     negate:true,",
						"     partitionBy('hash', 1),",
						"     broadcast: 'auto')~> exists1",
						"exists1 sink(allowSchemaDrift: true,",
						"     validateSchema: false,",
						"     partitionFileNames:['Emp not  exists in orders table.csv'],",
						"     skipDuplicateMapInputs: true,",
						"     skipDuplicateMapOutputs: true,",
						"     partitionBy('hash', 1)) ~> sink1"
					]
				}
			},
			"dependsOn": [
				"[concat(variables('factoryId'), '/datasets/EmployeeDataset')]",
				"[concat(variables('factoryId'), '/datasets/OrdersDataset')]",
				"[concat(variables('factoryId'), '/datasets/OutputDatasetCSVfiles')]",
				"[concat(variables('factoryId'), '/linkedServices/Linkedservice_storagedemoramm')]"
			]
		},
		{
			"name": "[concat(parameters('factoryName'), '/Filter Dataflow')]",
			"type": "Microsoft.DataFactory/factories/dataflows",
			"apiVersion": "2018-06-01",
			"properties": {
				"type": "MappingDataFlow",
				"typeProperties": {
					"sources": [
						{
							"dataset": {
								"referenceName": "CustomersDataset",
								"type": "DatasetReference"
							},
							"name": "source1"
						}
					],
					"sinks": [
						{
							"dataset": {
								"referenceName": "OutputDatasetCSVfiles",
								"type": "DatasetReference"
							},
							"name": "sink1"
						}
					],
					"transformations": [
						{
							"name": "filter1"
						}
					],
					"scriptLines": [
						"source(output(",
						"          CustomerID as string,",
						"          CustomerName as string,",
						"          ContactName as string,",
						"          Address as string,",
						"          City as string,",
						"          PostalCode as string,",
						"          Country as string",
						"     ),",
						"     allowSchemaDrift: true,",
						"     validateSchema: false,",
						"     ignoreNoFilesFound: false) ~> source1",
						"source1 filter(equals(Country, 'USA')) ~> filter1",
						"filter1 sink(allowSchemaDrift: true,",
						"     validateSchema: false,",
						"     partitionFileNames:['USA Country Filterd'],",
						"     skipDuplicateMapInputs: true,",
						"     skipDuplicateMapOutputs: true,",
						"     partitionBy('hash', 1)) ~> sink1"
					]
				}
			},
			"dependsOn": [
				"[concat(variables('factoryId'), '/datasets/CustomersDataset')]",
				"[concat(variables('factoryId'), '/datasets/OutputDatasetCSVfiles')]"
			]
		},
		{
			"name": "[concat(parameters('factoryName'), '/JoinOrdersCustData')]",
			"type": "Microsoft.DataFactory/factories/dataflows",
			"apiVersion": "2018-06-01",
			"properties": {
				"type": "MappingDataFlow",
				"typeProperties": {
					"sources": [
						{
							"dataset": {
								"referenceName": "CustomersDataset",
								"type": "DatasetReference"
							},
							"name": "CustomersData"
						},
						{
							"dataset": {
								"referenceName": "OrdersDataset",
								"type": "DatasetReference"
							},
							"name": "OrdersData"
						}
					],
					"sinks": [
						{
							"dataset": {
								"referenceName": "OutputDatasetCSVfiles",
								"type": "DatasetReference"
							},
							"name": "OutputData"
						}
					],
					"transformations": [
						{
							"name": "joinOrdersDataCustData"
						}
					],
					"scriptLines": [
						"source(output(",
						"          CustomerID as string,",
						"          CustomerName as string,",
						"          ContactName as string,",
						"          Address as string,",
						"          City as string,",
						"          PostalCode as string,",
						"          Country as string",
						"     ),",
						"     allowSchemaDrift: true,",
						"     validateSchema: false,",
						"     ignoreNoFilesFound: false) ~> CustomersData",
						"source(output(",
						"          OrderID as string,",
						"          CustomerID as string,",
						"          EmployeeID as string,",
						"          OrderDate as string,",
						"          ShipperID as string",
						"     ),",
						"     allowSchemaDrift: true,",
						"     validateSchema: false,",
						"     ignoreNoFilesFound: false) ~> OrdersData",
						"CustomersData, OrdersData join(CustomersData@CustomerID == OrdersData@CustomerID,",
						"     joinType:'inner',",
						"     matchType:'exact',",
						"     ignoreSpaces: false,",
						"     broadcast: 'auto')~> joinOrdersDataCustData",
						"joinOrdersDataCustData sink(allowSchemaDrift: true,",
						"     validateSchema: false,",
						"     partitionFileNames:['OrdersCustData'],",
						"     skipDuplicateMapInputs: true,",
						"     skipDuplicateMapOutputs: true,",
						"     mapColumn(",
						"          CustomerID = CustomersData@CustomerID,",
						"          CustomerName,",
						"          ContactName,",
						"          Address,",
						"          City,",
						"          PostalCode,",
						"          Country,",
						"          OrderID,",
						"          EmployeeID,",
						"          OrderDate,",
						"          ShipperID",
						"     ),",
						"     partitionBy('hash', 1)) ~> OutputData"
					]
				}
			},
			"dependsOn": [
				"[concat(variables('factoryId'), '/datasets/CustomersDataset')]",
				"[concat(variables('factoryId'), '/datasets/OrdersDataset')]",
				"[concat(variables('factoryId'), '/datasets/OutputDatasetCSVfiles')]"
			]
		},
		{
			"name": "[concat(parameters('factoryName'), '/Lookupdataflow')]",
			"type": "Microsoft.DataFactory/factories/dataflows",
			"apiVersion": "2018-06-01",
			"properties": {
				"description": "look up transformation preforming activity to join the customer and the orders table (look up activity is same as the left outer join)",
				"type": "MappingDataFlow",
				"typeProperties": {
					"sources": [
						{
							"dataset": {
								"referenceName": "CustomersDataset",
								"type": "DatasetReference"
							},
							"name": "CustomersTable"
						},
						{
							"dataset": {
								"referenceName": "OrdersDataset",
								"type": "DatasetReference"
							},
							"name": "OrdersTable"
						}
					],
					"sinks": [
						{
							"dataset": {
								"referenceName": "OutputDatasetCSVfiles",
								"type": "DatasetReference"
							},
							"name": "sink1"
						}
					],
					"transformations": [
						{
							"name": "lookup1"
						}
					],
					"scriptLines": [
						"source(output(",
						"          CustomerID as string,",
						"          CustomerName as string,",
						"          ContactName as string,",
						"          Address as string,",
						"          City as string,",
						"          PostalCode as string,",
						"          Country as string",
						"     ),",
						"     allowSchemaDrift: true,",
						"     validateSchema: false,",
						"     ignoreNoFilesFound: false) ~> CustomersTable",
						"source(output(",
						"          OrderID as string,",
						"          CustomerID as string,",
						"          EmployeeID as string,",
						"          OrderDate as string,",
						"          ShipperID as string",
						"     ),",
						"     allowSchemaDrift: true,",
						"     validateSchema: false,",
						"     ignoreNoFilesFound: false) ~> OrdersTable",
						"CustomersTable, OrdersTable lookup(CustomersTable@CustomerID == OrdersTable@CustomerID,",
						"     multiple: false,",
						"     pickup: 'any',",
						"     broadcast: 'auto')~> lookup1",
						"lookup1 sink(allowSchemaDrift: true,",
						"     validateSchema: false,",
						"     partitionFileNames:['Lookup cust order  (left join).csv'],",
						"     skipDuplicateMapInputs: true,",
						"     skipDuplicateMapOutputs: true,",
						"     partitionBy('hash', 1)) ~> sink1"
					]
				}
			},
			"dependsOn": [
				"[concat(variables('factoryId'), '/datasets/CustomersDataset')]",
				"[concat(variables('factoryId'), '/datasets/OrdersDataset')]",
				"[concat(variables('factoryId'), '/datasets/OutputDatasetCSVfiles')]"
			]
		},
		{
			"name": "[concat(parameters('factoryName'), '/PerrametaringDataflow')]",
			"type": "Microsoft.DataFactory/factories/dataflows",
			"apiVersion": "2018-06-01",
			"properties": {
				"type": "MappingDataFlow",
				"typeProperties": {
					"sources": [
						{
							"dataset": {
								"referenceName": "EmpMaheerDataDataset",
								"type": "DatasetReference"
							},
							"name": "source1"
						}
					],
					"sinks": [
						{
							"dataset": {
								"referenceName": "OutputDatasetCSVfiles",
								"type": "DatasetReference"
							},
							"name": "sink1"
						}
					],
					"transformations": [
						{
							"name": "filter1"
						}
					],
					"scriptLines": [
						"parameters{",
						"     DEPName as string",
						"}",
						"source(output(",
						"          id as string,",
						"          name as string,",
						"          gender as string,",
						"          country as string,",
						"          salary as string,",
						"          department as string",
						"     ),",
						"     allowSchemaDrift: true,",
						"     validateSchema: false,",
						"     ignoreNoFilesFound: false) ~> source1",
						"source1 filter(equals(department, $DEPName)) ~> filter1",
						"filter1 sink(allowSchemaDrift: true,",
						"     validateSchema: false,",
						"     partitionFileNames:['Perrametaring the dataflow.csv'],",
						"     skipDuplicateMapInputs: true,",
						"     skipDuplicateMapOutputs: true,",
						"     partitionBy('hash', 1)) ~> sink1"
					]
				}
			},
			"dependsOn": [
				"[concat(variables('factoryId'), '/datasets/EmpMaheerDataDataset')]",
				"[concat(variables('factoryId'), '/datasets/OutputDatasetCSVfiles')]"
			]
		},
		{
			"name": "[concat(parameters('factoryName'), '/Pivort different from aggregate dataflow')]",
			"type": "Microsoft.DataFactory/factories/dataflows",
			"apiVersion": "2018-06-01",
			"properties": {
				"description": "refer to pivot ",
				"type": "MappingDataFlow",
				"typeProperties": {
					"sources": [
						{
							"dataset": {
								"referenceName": "OrdersDataset",
								"type": "DatasetReference"
							},
							"name": "source1"
						}
					],
					"sinks": [
						{
							"dataset": {
								"referenceName": "OutputDatasetCSVfiles",
								"type": "DatasetReference"
							},
							"name": "sink1"
						}
					],
					"transformations": [
						{
							"name": "aggregate1"
						},
						{
							"name": "sort1"
						}
					],
					"scriptLines": [
						"source(output(",
						"          OrderID as string,",
						"          CustomerID as string,",
						"          EmployeeID as string,",
						"          OrderDate as string,",
						"          ShipperID as string",
						"     ),",
						"     allowSchemaDrift: true,",
						"     validateSchema: false,",
						"     ignoreNoFilesFound: false) ~> source1",
						"source1 aggregate(groupBy(EmployeeID,",
						"          ShipperID),",
						"     OrderID = count(OrderID)) ~> aggregate1",
						"aggregate1 sort(asc(ShipperID, true),",
						"     asc(EmployeeID, true)) ~> sort1",
						"sort1 sink(allowSchemaDrift: true,",
						"     validateSchema: false,",
						"     partitionFileNames:['Pivort ship and emp count aggregate .csv'],",
						"     skipDuplicateMapInputs: true,",
						"     skipDuplicateMapOutputs: true,",
						"     mapColumn(",
						"          ShipperID,",
						"          EmployeeID,",
						"          OrderID",
						"     ),",
						"     partitionBy('hash', 1)) ~> sink1"
					]
				}
			},
			"dependsOn": [
				"[concat(variables('factoryId'), '/datasets/OrdersDataset')]",
				"[concat(variables('factoryId'), '/datasets/OutputDatasetCSVfiles')]"
			]
		},
		{
			"name": "[concat(parameters('factoryName'), '/Pivot dataflow')]",
			"type": "Microsoft.DataFactory/factories/dataflows",
			"apiVersion": "2018-06-01",
			"properties": {
				"description": "Transforming the values in rows into new columns is pivot\nPivot is same as aggregate function, but it creates the new column instead for row. \nex: hear we grouped the shipperid and we pivot the emp id (as second group ny) so it creates the new column instead of row. ",
				"type": "MappingDataFlow",
				"typeProperties": {
					"sources": [
						{
							"dataset": {
								"referenceName": "OrdersDataset",
								"type": "DatasetReference"
							},
							"name": "source1"
						}
					],
					"sinks": [
						{
							"dataset": {
								"referenceName": "OutputDatasetCSVfiles",
								"type": "DatasetReference"
							},
							"name": "sink1"
						}
					],
					"transformations": [
						{
							"name": "pivot1"
						},
						{
							"name": "sort1"
						}
					],
					"scriptLines": [
						"source(output(",
						"          OrderID as string,",
						"          CustomerID as string,",
						"          EmployeeID as string,",
						"          OrderDate as string,",
						"          ShipperID as string",
						"     ),",
						"     allowSchemaDrift: true,",
						"     validateSchema: false,",
						"     ignoreNoFilesFound: false) ~> source1",
						"source1 pivot(groupBy(ShipperID),",
						"     pivotBy(EmployeeID),",
						"     {} = count(OrderID),",
						"     columnNaming: 'Emp ID:$N$V',",
						"     lateral: true) ~> pivot1",
						"pivot1 sort(asc(ShipperID, true)) ~> sort1",
						"sort1 sink(allowSchemaDrift: true,",
						"     validateSchema: false,",
						"     partitionFileNames:['Pivot shipper and emp id (agrate).csv'],",
						"     skipDuplicateMapInputs: true,",
						"     skipDuplicateMapOutputs: true,",
						"     partitionBy('hash', 1)) ~> sink1"
					]
				}
			},
			"dependsOn": [
				"[concat(variables('factoryId'), '/datasets/OrdersDataset')]",
				"[concat(variables('factoryId'), '/datasets/OutputDatasetCSVfiles')]"
			]
		},
		{
			"name": "[concat(parameters('factoryName'), '/Power query 1 - Emp')]",
			"type": "Microsoft.DataFactory/factories/dataflows",
			"apiVersion": "2018-06-01",
			"properties": {
				"description": "This Power Query in ADF performs data cleaning on the \"EmployeeDataset.\" It starts by removing the \"Photo\" and \"BirthDate\" columns, which are deemed unnecessary for the current analysis. Then, it standardizes the values in the \"Notes\" column by correcting the misspelled \"PHDD\" to \"PHD.\" This transformation ensures the dataset is clean and consistent for further data processing or analysis.",
				"type": "WranglingDataFlow",
				"typeProperties": {
					"sources": [
						{
							"name": "EmployeeDataset",
							"script": "source(allowSchemaDrift: true,\n\tvalidateSchema: false,\n\tignoreNoFilesFound: false) ~> EmployeeDataset",
							"dataset": {
								"referenceName": "EmployeeDataset",
								"type": "DatasetReference"
							}
						}
					],
					"script": "section Section1;\r\nshared EmployeeDataset = let AdfDoc = AzureStorage.BlobContents(\"https://storagedemoram.blob.core.windows.net/adfdemo/input/Employee.csv\"),Csv = Csv.Document(AdfDoc, [Delimiter = \",\", Encoding = TextEncoding.Utf8, QuoteStyle = QuoteStyle.Csv]), PromotedHeaders = Table.PromoteHeaders(Csv, [PromoteAllScalars = true]) in  PromotedHeaders;\r\nshared UserQuery = let Source = #\"EmployeeDataset\",\r\n  #\"Removed columns\" = Table.RemoveColumns(Source, {\"Photo\", \"BirthDate\"}),\r\n  #\"Replaced value\" = Table.ReplaceValue(#\"Removed columns\", \"PHD\", \"PHDD\", Replacer.ReplaceText, {\"Notes\"}) in #\"Replaced value\";\r\n",
					"documentLocale": "en-us"
				}
			},
			"dependsOn": [
				"[concat(variables('factoryId'), '/datasets/EmployeeDataset')]"
			]
		},
		{
			"name": "[concat(parameters('factoryName'), '/Powerquery 2  - Merge Queries')]",
			"type": "Microsoft.DataFactory/factories/dataflows",
			"apiVersion": "2018-06-01",
			"properties": {
				"description": "Merge Queries in Wrangling Data Flow is same as joins in SQL or joins in the dataflow ",
				"type": "WranglingDataFlow",
				"typeProperties": {
					"sources": [
						{
							"name": "CustomersDataset",
							"script": "source(allowSchemaDrift: true,\n\tvalidateSchema: false,\n\tignoreNoFilesFound: false) ~> CustomersDataset",
							"dataset": {
								"referenceName": "CustomersDataset",
								"type": "DatasetReference"
							}
						},
						{
							"name": "OrdersDataset",
							"script": "source(allowSchemaDrift: true,\n\tvalidateSchema: false,\n\tignoreNoFilesFound: false) ~> OrdersDataset",
							"dataset": {
								"referenceName": "OrdersDataset",
								"type": "DatasetReference"
							}
						}
					],
					"script": "section Section1;\r\nshared CustomersDataset = let AdfDoc = AzureStorage.BlobContents(\"https://storagedemoram.blob.core.windows.net/adfdemo/input/Customers.csv\"),Csv = Csv.Document(AdfDoc, [Delimiter = \",\", Encoding = TextEncoding.Utf8, QuoteStyle = QuoteStyle.Csv]), PromotedHeaders = Table.PromoteHeaders(Csv, [PromoteAllScalars = true]) in  PromotedHeaders;\r\nshared OrdersDataset = let AdfDoc = AzureStorage.BlobContents(\"https://storagedemoram.blob.core.windows.net/adfdemo/input/Orders.csv\"),Csv = Csv.Document(AdfDoc, [Delimiter = \",\", Encoding = TextEncoding.Utf8, QuoteStyle = QuoteStyle.Csv]), PromotedHeaders = Table.PromoteHeaders(Csv, [PromoteAllScalars = true]) in  PromotedHeaders;\r\nshared UserQuery = let Source = #\"CustomersDataset\",\r\n  #\"Merged queries\" = Table.NestedJoin(Source, {\"CustomerID\"}, OrdersDataset, {\"CustomerID\"}, \"OrdersDataset\", JoinKind.Inner),\r\n  #\"Expanded OrdersDataset\" = Table.ExpandTableColumn(#\"Merged queries\", \"OrdersDataset\", {\"OrderID\", \"EmployeeID\", \"OrderDate\", \"ShipperID\"}, {\"OrderID\", \"EmployeeID\", \"OrderDate\", \"ShipperID\"}),\r\n  #\"Removed columns\" = Table.RemoveColumns(#\"Expanded OrdersDataset\", {\"ContactName\", \"Address\", \"PostalCode\"}) in #\"Removed columns\";\r\n",
					"documentLocale": "en-us"
				}
			},
			"dependsOn": [
				"[concat(variables('factoryId'), '/datasets/CustomersDataset')]",
				"[concat(variables('factoryId'), '/datasets/OrdersDataset')]"
			]
		},
		{
			"name": "[concat(parameters('factoryName'), '/SelectDataflow')]",
			"type": "Microsoft.DataFactory/factories/dataflows",
			"apiVersion": "2018-06-01",
			"properties": {
				"type": "MappingDataFlow",
				"typeProperties": {
					"sources": [
						{
							"dataset": {
								"referenceName": "OrdersDataset",
								"type": "DatasetReference"
							},
							"name": "source1"
						}
					],
					"sinks": [
						{
							"dataset": {
								"referenceName": "OutputDatasetCSVfiles",
								"type": "DatasetReference"
							},
							"name": "sink1",
							"rejectedDataLinkedService": {
								"referenceName": "Linkedservice_storagedemoramm",
								"type": "LinkedServiceReference"
							}
						}
					],
					"transformations": [
						{
							"name": "select1"
						},
						{
							"name": "sort1"
						}
					],
					"scriptLines": [
						"source(output(",
						"          OrderID as string,",
						"          CustomerID as string,",
						"          EmployeeID as string,",
						"          OrderDate as string,",
						"          ShipperID as string",
						"     ),",
						"     allowSchemaDrift: true,",
						"     validateSchema: false,",
						"     ignoreNoFilesFound: false) ~> source1",
						"source1 select(mapColumn(",
						"          OrderDate,",
						"          OrderID",
						"     ),",
						"     skipDuplicateMapInputs: true,",
						"     skipDuplicateMapOutputs: true) ~> select1",
						"select1 sort(asc(OrderDate, true)) ~> sort1",
						"sort1 sink(allowSchemaDrift: true,",
						"     validateSchema: false,",
						"     partitionFileNames:['Select order ID & Date.csv'],",
						"     skipDuplicateMapInputs: true,",
						"     skipDuplicateMapOutputs: true,",
						"     partitionBy('hash', 1)) ~> sink1"
					]
				}
			},
			"dependsOn": [
				"[concat(variables('factoryId'), '/datasets/OrdersDataset')]",
				"[concat(variables('factoryId'), '/datasets/OutputDatasetCSVfiles')]",
				"[concat(variables('factoryId'), '/linkedServices/Linkedservice_storagedemoramm')]"
			]
		},
		{
			"name": "[concat(parameters('factoryName'), '/SortDataflow')]",
			"type": "Microsoft.DataFactory/factories/dataflows",
			"apiVersion": "2018-06-01",
			"properties": {
				"description": "sort transformation is like order by in SQL \nSort Transformation is performed to sort the table according to postal code ascending order. it displays the null values in the selected column and follows the rest \n",
				"type": "MappingDataFlow",
				"typeProperties": {
					"sources": [
						{
							"dataset": {
								"referenceName": "CustomersDataset",
								"type": "DatasetReference"
							},
							"name": "customers"
						}
					],
					"sinks": [
						{
							"dataset": {
								"referenceName": "OutputDatasetCSVfiles",
								"type": "DatasetReference"
							},
							"name": "sink1",
							"rejectedDataLinkedService": {
								"referenceName": "Linkedservice_storagedemoramm",
								"type": "LinkedServiceReference"
							}
						}
					],
					"transformations": [
						{
							"name": "sortName"
						}
					],
					"scriptLines": [
						"source(output(",
						"          CustomerID as string,",
						"          CustomerName as string,",
						"          ContactName as string,",
						"          Address as string,",
						"          City as string,",
						"          PostalCode as string,",
						"          Country as string",
						"     ),",
						"     allowSchemaDrift: true,",
						"     validateSchema: false,",
						"     ignoreNoFilesFound: false) ~> customers",
						"customers sort(asc(PostalCode, true)) ~> sortName",
						"sortName sink(allowSchemaDrift: true,",
						"     validateSchema: false,",
						"     partitionFileNames:['Sort postal code accending order (Order by)'],",
						"     skipDuplicateMapInputs: true,",
						"     skipDuplicateMapOutputs: true,",
						"     partitionBy('hash', 1)) ~> sink1"
					]
				}
			},
			"dependsOn": [
				"[concat(variables('factoryId'), '/datasets/CustomersDataset')]",
				"[concat(variables('factoryId'), '/datasets/OutputDatasetCSVfiles')]",
				"[concat(variables('factoryId'), '/linkedServices/Linkedservice_storagedemoramm')]"
			]
		},
		{
			"name": "[concat(parameters('factoryName'), '/SurrogateKeyDataflow')]",
			"type": "Microsoft.DataFactory/factories/dataflows",
			"apiVersion": "2018-06-01",
			"properties": {
				"description": "Surrogate key to add an increment key value to each row as a new column\nit is for adding something like serial number \nwe added the serial num to orders table",
				"type": "MappingDataFlow",
				"typeProperties": {
					"sources": [
						{
							"dataset": {
								"referenceName": "OrdersDataset",
								"type": "DatasetReference"
							},
							"name": "source1"
						}
					],
					"sinks": [
						{
							"dataset": {
								"referenceName": "OutputDatasetCSVfiles",
								"type": "DatasetReference"
							},
							"name": "sink1"
						}
					],
					"transformations": [
						{
							"name": "surrogateKey1"
						},
						{
							"name": "sort1"
						}
					],
					"scriptLines": [
						"source(output(",
						"          OrderID as string,",
						"          CustomerID as string,",
						"          EmployeeID as string,",
						"          OrderDate as string,",
						"          ShipperID as string",
						"     ),",
						"     allowSchemaDrift: true,",
						"     validateSchema: false,",
						"     ignoreNoFilesFound: false) ~> source1",
						"source1 keyGenerate(output({serial num} as long),",
						"     startAt: 1L,",
						"     stepValue: 1L) ~> surrogateKey1",
						"surrogateKey1 sort(asc({serial num}, true)) ~> sort1",
						"sort1 sink(allowSchemaDrift: true,",
						"     validateSchema: false,",
						"     partitionFileNames:['Surrogate key added Serial num to orders.csv'],",
						"     skipDuplicateMapInputs: true,",
						"     skipDuplicateMapOutputs: true,",
						"     mapColumn(",
						"          {serial num},",
						"          OrderID,",
						"          CustomerID,",
						"          EmployeeID,",
						"          OrderDate,",
						"          ShipperID",
						"     ),",
						"     partitionBy('hash', 1)) ~> sink1"
					]
				}
			},
			"dependsOn": [
				"[concat(variables('factoryId'), '/datasets/OrdersDataset')]",
				"[concat(variables('factoryId'), '/datasets/OutputDatasetCSVfiles')]"
			]
		},
		{
			"name": "[concat(parameters('factoryName'), '/Union shipperdataflow')]",
			"type": "Microsoft.DataFactory/factories/dataflows",
			"apiVersion": "2018-06-01",
			"properties": {
				"type": "MappingDataFlow",
				"typeProperties": {
					"sources": [
						{
							"dataset": {
								"referenceName": "Shiper1Dataset",
								"type": "DatasetReference"
							},
							"name": "shipper1"
						},
						{
							"dataset": {
								"referenceName": "Shipper2Dataset",
								"type": "DatasetReference"
							},
							"name": "shipper2"
						}
					],
					"sinks": [
						{
							"dataset": {
								"referenceName": "OutputDatasetCSVfiles",
								"type": "DatasetReference"
							},
							"name": "sink1"
						}
					],
					"transformations": [
						{
							"name": "unionshipper1and2"
						}
					],
					"scriptLines": [
						"source(allowSchemaDrift: true,",
						"     validateSchema: false,",
						"     ignoreNoFilesFound: false) ~> shipper1",
						"source(allowSchemaDrift: true,",
						"     validateSchema: false,",
						"     ignoreNoFilesFound: false) ~> shipper2",
						"shipper1, shipper2 union(byName: true)~> unionshipper1and2",
						"unionshipper1and2 sink(allowSchemaDrift: true,",
						"     validateSchema: false,",
						"     partitionFileNames:['Union of shipper 1 and 2.csv'],",
						"     skipDuplicateMapInputs: true,",
						"     skipDuplicateMapOutputs: true,",
						"     partitionBy('hash', 1)) ~> sink1"
					]
				}
			},
			"dependsOn": [
				"[concat(variables('factoryId'), '/datasets/Shiper1Dataset')]",
				"[concat(variables('factoryId'), '/datasets/Shipper2Dataset')]",
				"[concat(variables('factoryId'), '/datasets/OutputDatasetCSVfiles')]"
			]
		},
		{
			"name": "[concat(parameters('factoryName'), '/UnpivotDataflow')]",
			"type": "Microsoft.DataFactory/factories/dataflows",
			"apiVersion": "2018-06-01",
			"properties": {
				"description": "its ungrouping the columns\nTransforming the values in columns into new rows is unpivot. unpivot is opposite to pivot",
				"type": "MappingDataFlow",
				"typeProperties": {
					"sources": [
						{
							"dataset": {
								"referenceName": "PivortedShipperAndEmpfile",
								"type": "DatasetReference"
							},
							"name": "source1"
						}
					],
					"sinks": [
						{
							"dataset": {
								"referenceName": "OutputDatasetCSVfiles",
								"type": "DatasetReference"
							},
							"name": "sink1"
						}
					],
					"transformations": [
						{
							"name": "unpivot1"
						},
						{
							"name": "sort1"
						}
					],
					"scriptLines": [
						"source(output(",
						"          ShipperID as string,",
						"          {Emp ID:1} as string,",
						"          {Emp ID:2} as string,",
						"          {Emp ID:3} as string,",
						"          {Emp ID:4} as string,",
						"          {Emp ID:5} as string,",
						"          {Emp ID:6} as string,",
						"          {Emp ID:7} as string,",
						"          {Emp ID:8} as string,",
						"          {Emp ID:9} as string",
						"     ),",
						"     allowSchemaDrift: true,",
						"     validateSchema: false,",
						"     inferDriftedColumnTypes: true,",
						"     ignoreNoFilesFound: false) ~> source1",
						"source1 unpivot(output(",
						"          {EMP ID} as integer,",
						"          {order count} as string",
						"     ),",
						"     ungroupBy(ShipperID),",
						"     lateral: true,",
						"     ignoreNullPivots: true) ~> unpivot1",
						"unpivot1 sort(asc(ShipperID, true),",
						"     asc({EMP ID}, true)) ~> sort1",
						"sort1 sink(allowSchemaDrift: true,",
						"     validateSchema: false,",
						"     partitionFileNames:['UN Pivot shipper and emp id (agrate).csv'],",
						"     skipDuplicateMapInputs: true,",
						"     skipDuplicateMapOutputs: true,",
						"     partitionBy('hash', 1)) ~> sink1"
					]
				}
			},
			"dependsOn": [
				"[concat(variables('factoryId'), '/datasets/PivortedShipperAndEmpfile')]",
				"[concat(variables('factoryId'), '/datasets/OutputDatasetCSVfiles')]"
			]
		},
		{
			"name": "[concat(parameters('factoryName'), '/Window and densrank Dataflow')]",
			"type": "Microsoft.DataFactory/factories/dataflows",
			"apiVersion": "2018-06-01",
			"properties": {
				"description": "windows transformation in dataflow is like partition/over clause in SQL which divides the parts depends on our selection.\n\nhere we have separated the partition based on the department and added avg salary and Dens rank function to rank each row  ",
				"type": "MappingDataFlow",
				"typeProperties": {
					"sources": [
						{
							"dataset": {
								"referenceName": "EmpMaheerDataDataset",
								"type": "DatasetReference"
							},
							"name": "source1"
						}
					],
					"sinks": [
						{
							"dataset": {
								"referenceName": "OutputDatasetCSVfiles",
								"type": "DatasetReference"
							},
							"name": "sink1"
						}
					],
					"transformations": [
						{
							"name": "window1"
						},
						{
							"name": "surrogateKey1"
						}
					],
					"scriptLines": [
						"source(output(",
						"          id as integer,",
						"          name as string,",
						"          gender as string,",
						"          country as string,",
						"          salary as integer,",
						"          department as string",
						"     ),",
						"     allowSchemaDrift: true,",
						"     validateSchema: false,",
						"     ignoreNoFilesFound: false) ~> source1",
						"source1 window(over(department),",
						"     desc(salary, true),",
						"     AvgSalary = avg(salary),",
						"          DensRank = denseRank()) ~> window1",
						"window1 keyGenerate(output({Sl Number} as long),",
						"     startAt: 1L,",
						"     stepValue: 1L) ~> surrogateKey1",
						"surrogateKey1 sink(allowSchemaDrift: true,",
						"     validateSchema: false,",
						"     partitionFileNames:['Window Emp and Densrank.csv'],",
						"     skipDuplicateMapInputs: true,",
						"     skipDuplicateMapOutputs: true,",
						"     mapColumn(",
						"          {Sl Number},",
						"          id,",
						"          name,",
						"          gender,",
						"          country,",
						"          salary,",
						"          department,",
						"          AvgSalary,",
						"          DensRank",
						"     ),",
						"     partitionBy('hash', 1)) ~> sink1"
					]
				}
			},
			"dependsOn": [
				"[concat(variables('factoryId'), '/datasets/EmpMaheerDataDataset')]",
				"[concat(variables('factoryId'), '/datasets/OutputDatasetCSVfiles')]"
			]
		},
		{
			"name": "[concat(parameters('factoryName'), '/powerquery 3 - Groupby')]",
			"type": "Microsoft.DataFactory/factories/dataflows",
			"apiVersion": "2018-06-01",
			"properties": {
				"type": "WranglingDataFlow",
				"typeProperties": {
					"sources": [
						{
							"name": "OrdersDataset",
							"script": "source(allowSchemaDrift: true,\n\tvalidateSchema: false,\n\tignoreNoFilesFound: false) ~> OrdersDataset",
							"dataset": {
								"referenceName": "OrdersDataset",
								"type": "DatasetReference"
							}
						}
					],
					"script": "section Section1;\r\nshared OrdersDataset = let AdfDoc = AzureStorage.BlobContents(\"https://storagedemoram.blob.core.windows.net/adfdemo/input/Orders.csv\"),Csv = Csv.Document(AdfDoc, [Delimiter = \",\", Encoding = TextEncoding.Utf8, QuoteStyle = QuoteStyle.Csv]), PromotedHeaders = Table.PromoteHeaders(Csv, [PromoteAllScalars = true]) in  PromotedHeaders;\r\nshared UserQuery = let Source = #\"OrdersDataset\",\r\n  #\"Grouped rows\" = Table.Group(Source, {\"ShipperID\"}, {{\"Count of shippers\", each Table.RowCount(_), Int64.Type}}) in #\"Grouped rows\";\r\n",
					"documentLocale": "en-us"
				}
			},
			"dependsOn": [
				"[concat(variables('factoryId'), '/datasets/OrdersDataset')]"
			]
		}
	]
}