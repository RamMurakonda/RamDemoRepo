{
	"$schema": "http://schema.management.azure.com/schemas/2015-01-01/deploymentTemplate.json#",
	"contentVersion": "1.0.0.0",
	"parameters": {
		"factoryName": {
			"type": "string",
			"metadata": "Data Factory name",
			"defaultValue": "ADFdemoramm"
		}
	},
	"variables": {
		"factoryId": "[concat('Microsoft.DataFactory/factories/', parameters('factoryName'))]"
	},
	"resources": [
		{
			"name": "[concat(parameters('factoryName'), '/PivortedShipperAndEmpfile')]",
			"type": "Microsoft.DataFactory/factories/datasets",
			"apiVersion": "2018-06-01",
			"properties": {
				"linkedServiceName": {
					"referenceName": "Linkedservice_storagedemoramm",
					"type": "LinkedServiceReference"
				},
				"annotations": [],
				"type": "DelimitedText",
				"typeProperties": {
					"location": {
						"type": "AzureBlobStorageLocation",
						"fileName": "Pivot shipper and emp id (agrate).csv",
						"folderPath": "output",
						"container": "adfdemo"
					},
					"columnDelimiter": ",",
					"escapeChar": "\\",
					"firstRowAsHeader": true,
					"quoteChar": "\""
				},
				"schema": [
					{
						"name": "ShipperID",
						"type": "String"
					},
					{
						"name": "Emp ID:1",
						"type": "String"
					},
					{
						"name": "Emp ID:2",
						"type": "String"
					},
					{
						"name": "Emp ID:3",
						"type": "String"
					},
					{
						"name": "Emp ID:4",
						"type": "String"
					},
					{
						"name": "Emp ID:5",
						"type": "String"
					},
					{
						"name": "Emp ID:6",
						"type": "String"
					},
					{
						"name": "Emp ID:7",
						"type": "String"
					},
					{
						"name": "Emp ID:8",
						"type": "String"
					},
					{
						"name": "Emp ID:9",
						"type": "String"
					}
				]
			},
			"dependsOn": []
		},
		{
			"name": "[concat(parameters('factoryName'), '/ProductsDataset')]",
			"type": "Microsoft.DataFactory/factories/datasets",
			"apiVersion": "2018-06-01",
			"properties": {
				"linkedServiceName": {
					"referenceName": "Linkedservice_storagedemoramm",
					"type": "LinkedServiceReference"
				},
				"annotations": [],
				"type": "DelimitedText",
				"typeProperties": {
					"location": {
						"type": "AzureBlobStorageLocation",
						"fileName": "Products.csv",
						"folderPath": "input",
						"container": "adfdemo"
					},
					"columnDelimiter": ",",
					"escapeChar": "\\",
					"firstRowAsHeader": true,
					"quoteChar": "\""
				},
				"schema": [
					{
						"name": "ProductID",
						"type": "String"
					},
					{
						"name": "ProductName",
						"type": "String"
					},
					{
						"name": "SupplierID",
						"type": "String"
					},
					{
						"name": "CategoryID",
						"type": "String"
					},
					{
						"name": "Unit",
						"type": "String"
					},
					{
						"name": "Price",
						"type": "String"
					}
				]
			},
			"dependsOn": []
		},
		{
			"name": "[concat(parameters('factoryName'), '/Shiper1Dataset')]",
			"type": "Microsoft.DataFactory/factories/datasets",
			"apiVersion": "2018-06-01",
			"properties": {
				"linkedServiceName": {
					"referenceName": "Linkedservice_storagedemoramm",
					"type": "LinkedServiceReference"
				},
				"annotations": [],
				"type": "DelimitedText",
				"typeProperties": {
					"location": {
						"type": "AzureBlobStorageLocation",
						"fileName": "Shipper1.csv",
						"folderPath": "input",
						"container": "adfdemo"
					},
					"columnDelimiter": ",",
					"escapeChar": "\\",
					"firstRowAsHeader": true,
					"quoteChar": "\""
				},
				"schema": []
			},
			"dependsOn": []
		},
		{
			"name": "[concat(parameters('factoryName'), '/Shipper2Dataset')]",
			"type": "Microsoft.DataFactory/factories/datasets",
			"apiVersion": "2018-06-01",
			"properties": {
				"linkedServiceName": {
					"referenceName": "Linkedservice_storagedemoramm",
					"type": "LinkedServiceReference"
				},
				"annotations": [],
				"type": "DelimitedText",
				"typeProperties": {
					"location": {
						"type": "AzureBlobStorageLocation",
						"fileName": "Shipper2.csv",
						"folderPath": "input",
						"container": "adfdemo"
					},
					"columnDelimiter": ",",
					"escapeChar": "\\",
					"firstRowAsHeader": true,
					"quoteChar": "\""
				},
				"schema": []
			},
			"dependsOn": []
		},
		{
			"name": "[concat(parameters('factoryName'), '/ShipperDataset')]",
			"type": "Microsoft.DataFactory/factories/datasets",
			"apiVersion": "2018-06-01",
			"properties": {
				"linkedServiceName": {
					"referenceName": "Linkedservice_storagedemoramm",
					"type": "LinkedServiceReference"
				},
				"annotations": [],
				"type": "DelimitedText",
				"typeProperties": {
					"location": {
						"type": "AzureBlobStorageLocation",
						"fileName": "Shippers.csv",
						"folderPath": "input",
						"container": "adfdemo"
					},
					"columnDelimiter": ",",
					"escapeChar": "\\",
					"firstRowAsHeader": true,
					"quoteChar": "\""
				},
				"schema": [
					{
						"name": "ShipperID",
						"type": "String"
					},
					{
						"name": "ShipperName",
						"type": "String"
					},
					{
						"name": "Phone",
						"type": "String"
					}
				]
			},
			"dependsOn": []
		},
		{
			"name": "[concat(parameters('factoryName'), '/Sourcedataset')]",
			"type": "Microsoft.DataFactory/factories/datasets",
			"apiVersion": "2018-06-01",
			"properties": {
				"linkedServiceName": {
					"referenceName": "Linkedservice_storagedemoramm",
					"type": "LinkedServiceReference"
				},
				"annotations": [],
				"type": "DelimitedText",
				"typeProperties": {
					"location": {
						"type": "AzureBlobStorageLocation",
						"fileName": "EmpSourceData.txt",
						"folderPath": "input",
						"container": "adfdemo"
					},
					"columnDelimiter": ",",
					"escapeChar": "\\",
					"firstRowAsHeader": true,
					"quoteChar": "\""
				},
				"schema": [
					{
						"name": "Seetharam",
						"type": "String"
					},
					{
						"name": " Male",
						"type": "String"
					},
					{
						"name": " 123",
						"type": "String"
					}
				]
			},
			"dependsOn": []
		},
		{
			"name": "[concat(parameters('factoryName'), '/pipeline1 - copying TXT File')]",
			"type": "Microsoft.DataFactory/factories/pipelines",
			"apiVersion": "2018-06-01",
			"properties": {
				"activities": [
					{
						"name": "Copy data1",
						"description": "Coping the data.txt file from the input folder to output folder in adfdemo container",
						"type": "Copy",
						"dependsOn": [],
						"policy": {
							"timeout": "0.12:00:00",
							"retry": 0,
							"retryIntervalInSeconds": 30,
							"secureOutput": false,
							"secureInput": false
						},
						"userProperties": [
							{
								"name": "Source",
								"value": "adfdemo/input/data.txt"
							},
							{
								"name": "Destination",
								"value": "adfdemo/output/data.txt"
							}
						],
						"typeProperties": {
							"source": {
								"type": "BinarySource",
								"storeSettings": {
									"type": "AzureBlobStorageReadSettings",
									"recursive": true
								},
								"formatSettings": {
									"type": "BinaryReadSettings"
								}
							},
							"sink": {
								"type": "BinarySink",
								"storeSettings": {
									"type": "AzureBlobStorageWriteSettings"
								}
							},
							"enableStaging": false
						},
						"inputs": [
							{
								"referenceName": "InputDataDataSet",
								"type": "DatasetReference",
								"parameters": {}
							}
						],
						"outputs": [
							{
								"referenceName": "OutputDataDataset",
								"type": "DatasetReference",
								"parameters": {}
							}
						]
					}
				],
				"policy": {
					"elapsedTimeMetric": {}
				},
				"annotations": [],
				"lastPublishTime": "2024-06-16T05:43:15Z"
			},
			"dependsOn": []
		},
		{
			"name": "[concat(parameters('factoryName'), '/pipeline10 - Until Activity')]",
			"type": "Microsoft.DataFactory/factories/pipelines",
			"apiVersion": "2018-06-01",
			"properties": {
				"activities": [
					{
						"name": "Until1",
						"description": "in the Until loop \nThe flag value FileAvailabe variable tells file available or not available, the default value if false for the 1st time as the default value is false then it goes inside the loop and opens the activity's in the loop.\nthen using the GET METADATA we are getting the metadata of the file whether the file exists or not and then followed by the if condition, if its true  and file is available it sets the variable to True using the SETVERIABLE so the loop end here and followed by the copy data activity\n\nIF the value is false it means file is not available then it waits for 60 seconds before running the until loop again ",
						"type": "Until",
						"dependsOn": [],
						"userProperties": [],
						"typeProperties": {
							"expression": {
								"value": "@bool(variables('FileAvailable'))",
								"type": "Expression"
							},
							"activities": [
								{
									"name": "Get Metadata1",
									"type": "GetMetadata",
									"dependsOn": [],
									"policy": {
										"timeout": "0.12:00:00",
										"retry": 0,
										"retryIntervalInSeconds": 30,
										"secureOutput": false,
										"secureInput": false
									},
									"userProperties": [],
									"typeProperties": {
										"dataset": {
											"referenceName": "InputDataDataSet",
											"type": "DatasetReference",
											"parameters": {}
										},
										"fieldList": [
											"exists"
										],
										"storeSettings": {
											"type": "AzureBlobStorageReadSettings",
											"recursive": true,
											"enablePartitionDiscovery": false
										},
										"formatSettings": {
											"type": "BinaryReadSettings"
										}
									}
								},
								{
									"name": "If Condition1",
									"type": "IfCondition",
									"dependsOn": [
										{
											"activity": "Get Metadata1",
											"dependencyConditions": [
												"Succeeded"
											]
										}
									],
									"userProperties": [],
									"typeProperties": {
										"expression": {
											"value": "@activity('Get Metadata1').outputbinary()",
											"type": "Expression"
										},
										"ifFalseActivities": [
											{
												"name": "Wait1",
												"type": "Wait",
												"dependsOn": [],
												"userProperties": [],
												"typeProperties": {
													"waitTimeInSeconds": 60
												}
											}
										],
										"ifTrueActivities": [
											{
												"name": "Set variable1",
												"type": "SetVariable",
												"dependsOn": [],
												"policy": {
													"secureOutput": false,
													"secureInput": false
												},
												"userProperties": [],
												"typeProperties": {
													"variableName": "FileAvailable",
													"value": "True "
												}
											}
										]
									}
								}
							],
							"timeout": "0.00:02:00"
						}
					},
					{
						"name": "Copy data1",
						"description": "Copying the file after completing the until loop and found the metadata of that file ",
						"type": "Copy",
						"dependsOn": [
							{
								"activity": "Until1",
								"dependencyConditions": [
									"Succeeded"
								]
							}
						],
						"policy": {
							"timeout": "0.12:00:00",
							"retry": 0,
							"retryIntervalInSeconds": 30,
							"secureOutput": false,
							"secureInput": false
						},
						"userProperties": [
							{
								"name": "Source",
								"value": "adfdemo/input/data.txt"
							},
							{
								"name": "Destination",
								"value": "adfdemo/output/"
							}
						],
						"typeProperties": {
							"source": {
								"type": "BinarySource",
								"storeSettings": {
									"type": "AzureBlobStorageReadSettings",
									"recursive": true
								},
								"formatSettings": {
									"type": "BinaryReadSettings"
								}
							},
							"sink": {
								"type": "BinarySink",
								"storeSettings": {
									"type": "AzureBlobStorageWriteSettings"
								}
							},
							"enableStaging": false
						},
						"inputs": [
							{
								"referenceName": "InputDataDataSet",
								"type": "DatasetReference",
								"parameters": {}
							}
						],
						"outputs": [
							{
								"referenceName": "OutputFolderDataset",
								"type": "DatasetReference",
								"parameters": {}
							}
						]
					}
				],
				"policy": {
					"elapsedTimeMetric": {}
				},
				"variables": {
					"FileAvailable": {
						"type": "String",
						"defaultValue": "Flase"
					}
				},
				"annotations": [],
				"lastPublishTime": "2024-06-16T20:09:31Z"
			},
			"dependsOn": []
		},
		{
			"name": "[concat(parameters('factoryName'), '/pipeline2 - SQL Database')]",
			"type": "Microsoft.DataFactory/factories/pipelines",
			"apiVersion": "2018-06-01",
			"properties": {
				"activities": [
					{
						"name": "Copy data1",
						"type": "Copy",
						"dependsOn": [],
						"policy": {
							"timeout": "0.12:00:00",
							"retry": 0,
							"retryIntervalInSeconds": 30,
							"secureOutput": false,
							"secureInput": false
						},
						"userProperties": [],
						"typeProperties": {
							"source": {
								"type": "SqlServerSource",
								"queryTimeout": "02:00:00",
								"partitionOption": "None"
							},
							"sink": {
								"type": "SqlServerSink",
								"writeBehavior": "insert",
								"sqlWriterUseTableLock": false
							},
							"enableStaging": false,
							"translator": {
								"type": "TabularTranslator",
								"typeConversion": true,
								"typeConversionSettings": {
									"allowDataTruncation": true,
									"treatBooleanAsNumber": false
								}
							}
						},
						"inputs": [
							{
								"referenceName": "Dataset_SqlTable",
								"type": "DatasetReference",
								"parameters": {
									"DBNamefromDataset": {
										"value": "@pipeline().parameters.SourceTable",
										"type": "Expression"
									},
									"TableName": {
										"value": "@pipeline().parameters.DbNamefromPipeline",
										"type": "Expression"
									}
								}
							}
						],
						"outputs": [
							{
								"referenceName": "Dataset_SqlTable",
								"type": "DatasetReference",
								"parameters": {
									"DBNamefromDataset": {
										"value": "@pipeline().parameters.DestinationTable",
										"type": "Expression"
									},
									"TableName": {
										"value": "@pipeline().parameters.DbNamefromPipeline",
										"type": "Expression"
									}
								}
							}
						]
					}
				],
				"policy": {
					"elapsedTimeMetric": {}
				},
				"parameters": {
					"SourceTable": {
						"type": "string"
					},
					"DbNamefromPipeline": {
						"type": "string"
					},
					"DestinationTable": {
						"type": "string"
					}
				},
				"annotations": [],
				"lastPublishTime": "2024-06-15T02:37:16Z"
			},
			"dependsOn": []
		},
		{
			"name": "[concat(parameters('factoryName'), '/pipeline3 - Copying CSV File MAPING')]",
			"type": "Microsoft.DataFactory/factories/pipelines",
			"apiVersion": "2018-06-01",
			"properties": {
				"activities": [
					{
						"name": "Copy data1",
						"description": "Mapping the tabular data in csv file in the sourcedataset and copying the mapped file to the DestinationDataset",
						"type": "Copy",
						"dependsOn": [],
						"policy": {
							"timeout": "0.12:00:00",
							"retry": 0,
							"retryIntervalInSeconds": 30,
							"secureOutput": false,
							"secureInput": false
						},
						"userProperties": [
							{
								"name": "Source",
								"value": "adfdemo/input/EmpSourceData.txt"
							},
							{
								"name": "Destination",
								"value": "adfdemo/output/"
							}
						],
						"typeProperties": {
							"source": {
								"type": "DelimitedTextSource",
								"storeSettings": {
									"type": "AzureBlobStorageReadSettings",
									"recursive": true,
									"enablePartitionDiscovery": false
								},
								"formatSettings": {
									"type": "DelimitedTextReadSettings"
								}
							},
							"sink": {
								"type": "DelimitedTextSink",
								"storeSettings": {
									"type": "AzureBlobStorageWriteSettings"
								},
								"formatSettings": {
									"type": "DelimitedTextWriteSettings",
									"quoteAllText": true,
									"fileExtension": ".txt"
								}
							},
							"enableStaging": false,
							"translator": {
								"type": "TabularTranslator",
								"mappings": [
									{
										"source": {
											"name": " Male",
											"type": "String",
											"physicalType": "String"
										},
										"sink": {
											"name": " Male",
											"type": "String",
											"physicalType": "String"
										}
									},
									{
										"source": {
											"name": "Seetharam",
											"type": "String",
											"physicalType": "String"
										},
										"sink": {
											"name": "Seetharam",
											"type": "String",
											"physicalType": "String"
										}
									},
									{
										"source": {
											"name": " 123",
											"type": "String",
											"physicalType": "String"
										},
										"sink": {
											"name": " 123",
											"type": "String",
											"physicalType": "String"
										}
									}
								],
								"typeConversion": true,
								"typeConversionSettings": {
									"allowDataTruncation": true,
									"treatBooleanAsNumber": false
								}
							}
						},
						"inputs": [
							{
								"referenceName": "Sourcedataset",
								"type": "DatasetReference",
								"parameters": {}
							}
						],
						"outputs": [
							{
								"referenceName": "DestinationDataset",
								"type": "DatasetReference",
								"parameters": {}
							}
						]
					}
				],
				"policy": {
					"elapsedTimeMetric": {}
				},
				"annotations": [],
				"lastPublishTime": "2024-06-16T05:43:15Z"
			},
			"dependsOn": [
				"[concat(variables('factoryId'), '/datasets/Sourcedataset')]"
			]
		},
		{
			"name": "[concat(parameters('factoryName'), '/pipeline4 - Delecting File')]",
			"type": "Microsoft.DataFactory/factories/pipelines",
			"apiVersion": "2018-06-01",
			"properties": {
				"activities": [
					{
						"name": "Delete1",
						"description": "Delecting all the txt files in the output folder in the adfdemo container using delete activity ",
						"type": "Delete",
						"dependsOn": [],
						"policy": {
							"timeout": "0.12:00:00",
							"retry": 0,
							"retryIntervalInSeconds": 30,
							"secureOutput": false,
							"secureInput": false
						},
						"userProperties": [
							{
								"name": "FilesDaleted",
								"value": "All TXT Files In Output folder of Adefdemo container"
							}
						],
						"typeProperties": {
							"dataset": {
								"referenceName": "OutputFolderDataset",
								"type": "DatasetReference",
								"parameters": {}
							},
							"logStorageSettings": {
								"linkedServiceName": {
									"referenceName": "Linkedservice_storagedemoramm",
									"type": "LinkedServiceReference"
								},
								"path": "adfdemo/output"
							},
							"enableLogging": true,
							"storeSettings": {
								"type": "AzureBlobStorageReadSettings",
								"recursive": true,
								"enablePartitionDiscovery": false
							}
						}
					}
				],
				"policy": {
					"elapsedTimeMetric": {}
				},
				"annotations": [],
				"lastPublishTime": "2024-06-16T05:43:15Z"
			},
			"dependsOn": []
		},
		{
			"name": "[concat(parameters('factoryName'), '/pipeline6 - Foreach CopyData')]",
			"type": "Microsoft.DataFactory/factories/pipelines",
			"apiVersion": "2018-06-01",
			"properties": {
				"activities": [
					{
						"name": "ForEach1",
						"description": "Copying The Data.txt file into 3 different folders with the 3 different file names in the same container ",
						"type": "ForEach",
						"dependsOn": [],
						"userProperties": [],
						"typeProperties": {
							"items": {
								"value": "@pipeline().parameters.OutputFolders",
								"type": "Expression"
							},
							"isSequential": true,
							"activities": [
								{
									"name": "Copy data1",
									"description": "Copying The Data.txt file into 3 different folders with the 3 different file names ",
									"type": "Copy",
									"dependsOn": [],
									"policy": {
										"timeout": "0.12:00:00",
										"retry": 0,
										"retryIntervalInSeconds": 30,
										"secureOutput": false,
										"secureInput": false
									},
									"userProperties": [
										{
											"name": "Source",
											"value": "adfdemo/input/data.txt"
										},
										{
											"name": "Destination",
											"value": "adfdemo/@{item()}/"
										}
									],
									"typeProperties": {
										"source": {
											"type": "BinarySource",
											"storeSettings": {
												"type": "AzureBlobStorageReadSettings",
												"recursive": true
											},
											"formatSettings": {
												"type": "BinaryReadSettings"
											}
										},
										"sink": {
											"type": "BinarySink",
											"storeSettings": {
												"type": "AzureBlobStorageWriteSettings"
											}
										},
										"enableStaging": false
									},
									"inputs": [
										{
											"referenceName": "InputDataDataSet",
											"type": "DatasetReference",
											"parameters": {}
										}
									],
									"outputs": [
										{
											"referenceName": "DemoramOutput",
											"type": "DatasetReference",
											"parameters": {
												"FolderName": {
													"value": "@item()",
													"type": "Expression"
												}
											}
										}
									]
								}
							]
						}
					}
				],
				"policy": {
					"elapsedTimeMetric": {}
				},
				"parameters": {
					"OutputFolders": {
						"type": "array",
						"defaultValue": [
							"output1/Data1.txt",
							"output2/Data2.txt",
							"output3/data3.txt"
						]
					}
				},
				"annotations": [],
				"lastPublishTime": "2024-06-16T02:27:02Z"
			},
			"dependsOn": []
		},
		{
			"name": "[concat(parameters('factoryName'), '/pipeline7 ForEach Deleting - pipline6')]",
			"type": "Microsoft.DataFactory/factories/pipelines",
			"apiVersion": "2018-06-01",
			"properties": {
				"activities": [
					{
						"name": "ForEachDeleting",
						"description": "Deleting the Folders copied / created in pipeline6 using Foreach",
						"type": "ForEach",
						"dependsOn": [],
						"userProperties": [],
						"typeProperties": {
							"items": {
								"value": "@pipeline().parameters.OutputFoldernames",
								"type": "Expression"
							},
							"isSequential": true,
							"activities": [
								{
									"name": "Delete1",
									"type": "Delete",
									"dependsOn": [],
									"policy": {
										"timeout": "0.12:00:00",
										"retry": 0,
										"retryIntervalInSeconds": 30,
										"secureOutput": false,
										"secureInput": false
									},
									"userProperties": [],
									"typeProperties": {
										"dataset": {
											"referenceName": "DemoramOutput",
											"type": "DatasetReference",
											"parameters": {
												"FolderName": {
													"value": "@item()",
													"type": "Expression"
												}
											}
										},
										"logStorageSettings": {
											"linkedServiceName": {
												"referenceName": "Linkedservice_storagedemoramm",
												"type": "LinkedServiceReference"
											},
											"path": {
												"value": "@item()",
												"type": "Expression"
											}
										},
										"enableLogging": true,
										"storeSettings": {
											"type": "AzureBlobStorageReadSettings",
											"recursive": true,
											"enablePartitionDiscovery": false
										}
									}
								}
							]
						}
					}
				],
				"policy": {
					"elapsedTimeMetric": {}
				},
				"parameters": {
					"OutputFoldernames": {
						"type": "array",
						"defaultValue": [
							"output1/Data1.txt",
							"output2/Data2.txt",
							"output3/data3.txt"
						]
					}
				},
				"annotations": [],
				"lastPublishTime": "2024-06-16T02:22:29Z"
			},
			"dependsOn": []
		},
		{
			"name": "[concat(parameters('factoryName'), '/pipeline8 IF Condition1')]",
			"type": "Microsoft.DataFactory/factories/pipelines",
			"apiVersion": "2018-06-01",
			"properties": {
				"activities": [
					{
						"name": "If Condition1",
						"type": "IfCondition",
						"dependsOn": [],
						"userProperties": [],
						"typeProperties": {
							"expression": {
								"value": "@bool(pipeline().parameters.Copytooutput1)",
								"type": "Expression"
							},
							"ifFalseActivities": [
								{
									"name": "Copy data2",
									"type": "Copy",
									"dependsOn": [],
									"policy": {
										"timeout": "0.12:00:00",
										"retry": 0,
										"retryIntervalInSeconds": 30,
										"secureOutput": false,
										"secureInput": false
									},
									"userProperties": [],
									"typeProperties": {
										"source": {
											"type": "BinarySource",
											"storeSettings": {
												"type": "AzureBlobStorageReadSettings",
												"recursive": true
											},
											"formatSettings": {
												"type": "BinaryReadSettings"
											}
										},
										"sink": {
											"type": "BinarySink",
											"storeSettings": {
												"type": "AzureBlobStorageWriteSettings"
											}
										},
										"enableStaging": false
									},
									"inputs": [
										{
											"referenceName": "InputDataDataSet",
											"type": "DatasetReference",
											"parameters": {}
										}
									],
									"outputs": [
										{
											"referenceName": "OutputLocationDataset",
											"type": "DatasetReference",
											"parameters": {
												"OutputFolder": {
													"value": "@pipeline().parameters.Output2Folder",
													"type": "Expression"
												}
											}
										}
									]
								}
							],
							"ifTrueActivities": [
								{
									"name": "Copy data1",
									"type": "Copy",
									"dependsOn": [],
									"policy": {
										"timeout": "0.12:00:00",
										"retry": 0,
										"retryIntervalInSeconds": 30,
										"secureOutput": false,
										"secureInput": false
									},
									"userProperties": [],
									"typeProperties": {
										"source": {
											"type": "BinarySource",
											"storeSettings": {
												"type": "AzureBlobStorageReadSettings",
												"recursive": true
											},
											"formatSettings": {
												"type": "BinaryReadSettings"
											}
										},
										"sink": {
											"type": "BinarySink",
											"storeSettings": {
												"type": "AzureBlobStorageWriteSettings"
											}
										},
										"enableStaging": false
									},
									"inputs": [
										{
											"referenceName": "InputDataDataSet",
											"type": "DatasetReference",
											"parameters": {}
										}
									],
									"outputs": [
										{
											"referenceName": "OutputLocationDataset",
											"type": "DatasetReference",
											"parameters": {
												"OutputFolder": {
													"value": "@pipeline().parameters.Output1Folder",
													"type": "Expression"
												}
											}
										}
									]
								}
							]
						}
					}
				],
				"policy": {
					"elapsedTimeMetric": {}
				},
				"parameters": {
					"Copytooutput1": {
						"type": "string",
						"defaultValue": "true"
					},
					"Output1Folder": {
						"type": "string",
						"defaultValue": "Output1"
					},
					"Output2Folder": {
						"type": "string",
						"defaultValue": "Output2"
					}
				},
				"annotations": [],
				"lastPublishTime": "2024-06-16T05:07:28Z"
			},
			"dependsOn": []
		},
		{
			"name": "[concat(parameters('factoryName'), '/AggregateTotalOrdersbyShipdataflow')]",
			"type": "Microsoft.DataFactory/factories/dataflows",
			"apiVersion": "2018-06-01",
			"properties": {
				"type": "MappingDataFlow",
				"typeProperties": {
					"sources": [
						{
							"dataset": {
								"referenceName": "OrdersDataset",
								"type": "DatasetReference"
							},
							"name": "Orders"
						},
						{
							"dataset": {
								"referenceName": "ShipperDataset",
								"type": "DatasetReference"
							},
							"name": "Shippers"
						}
					],
					"sinks": [
						{
							"dataset": {
								"referenceName": "OutputDatasetCSVfiles",
								"type": "DatasetReference"
							},
							"name": "sink1"
						}
					],
					"transformations": [
						{
							"name": "aggregate1"
						},
						{
							"name": "join1"
						}
					],
					"scriptLines": [
						"source(output(",
						"          OrderID as string,",
						"          CustomerID as string,",
						"          EmployeeID as string,",
						"          OrderDate as string,",
						"          ShipperID as string",
						"     ),",
						"     allowSchemaDrift: true,",
						"     validateSchema: false,",
						"     ignoreNoFilesFound: false) ~> Orders",
						"source(output(",
						"          ShipperID as string,",
						"          ShipperName as string,",
						"          Phone as string",
						"     ),",
						"     allowSchemaDrift: true,",
						"     validateSchema: false,",
						"     ignoreNoFilesFound: false) ~> Shippers",
						"Orders aggregate(groupBy(ShipperID),",
						"     TotalOrders = count(OrderID)) ~> aggregate1",
						"aggregate1, Shippers join(aggregate1@ShipperID == Shippers@ShipperID,",
						"     joinType:'inner',",
						"     matchType:'exact',",
						"     ignoreSpaces: false,",
						"     broadcast: 'auto')~> join1",
						"join1 sink(allowSchemaDrift: true,",
						"     validateSchema: false,",
						"     partitionFileNames:['Orders By Shippers.csv'],",
						"     skipDuplicateMapInputs: true,",
						"     skipDuplicateMapOutputs: true,",
						"     mapColumn(",
						"          ShipperID = aggregate1@ShipperID,",
						"          ShipperName,",
						"          TotalOrders",
						"     ),",
						"     partitionBy('hash', 1)) ~> sink1"
					]
				}
			},
			"dependsOn": [
				"[concat(variables('factoryId'), '/datasets/ShipperDataset')]"
			]
		},
		{
			"name": "[concat(parameters('factoryName'), '/AlterRowDataflow')]",
			"type": "Microsoft.DataFactory/factories/dataflows",
			"apiVersion": "2018-06-01",
			"properties": {
				"description": "Alter Row transformation used to insert, update, delete, and upset on rows based on the condition.\nexample: where clause with insert/delete statements in SQL ",
				"type": "MappingDataFlow",
				"typeProperties": {
					"sources": [
						{
							"dataset": {
								"referenceName": "EmpMaheerDataDataset",
								"type": "DatasetReference"
							},
							"name": "source1"
						}
					],
					"sinks": [
						{
							"dataset": {
								"referenceName": "EmpMaheerDataDataset",
								"type": "DatasetReference"
							},
							"name": "sink1"
						}
					],
					"transformations": [
						{
							"name": "alterRow1"
						}
					],
					"scriptLines": [
						"source(output(",
						"          id as integer,",
						"          name as string,",
						"          gender as string,",
						"          country as string,",
						"          salary as integer,",
						"          department as string",
						"     ),",
						"     allowSchemaDrift: true,",
						"     validateSchema: false,",
						"     ignoreNoFilesFound: false) ~> source1",
						"source1 alterRow(deleteIf(gender=='male'),",
						"     updateIf(department=='IT')) ~> alterRow1",
						"alterRow1 sink(allowSchemaDrift: true,",
						"     validateSchema: false,",
						"     input(",
						"          id as string,",
						"          name as string,",
						"          gender as string,",
						"          country as string,",
						"          salary as string,",
						"          department as string",
						"     ),",
						"     skipDuplicateMapInputs: true,",
						"     skipDuplicateMapOutputs: true) ~> sink1"
					]
				}
			},
			"dependsOn": []
		},
		{
			"name": "[concat(parameters('factoryName'), '/ConditionlSplitDataflow')]",
			"type": "Microsoft.DataFactory/factories/dataflows",
			"apiVersion": "2018-06-01",
			"properties": {
				"type": "MappingDataFlow",
				"typeProperties": {
					"sources": [
						{
							"dataset": {
								"referenceName": "OrdersDataset",
								"type": "DatasetReference"
							},
							"name": "source1"
						}
					],
					"sinks": [
						{
							"dataset": {
								"referenceName": "OutputDatasetCSVfiles",
								"type": "DatasetReference"
							},
							"name": "Ship1Sink"
						},
						{
							"dataset": {
								"referenceName": "OutputDatasetCSVfiles",
								"type": "DatasetReference"
							},
							"name": "Ship2Sink"
						},
						{
							"dataset": {
								"referenceName": "OutputDatasetCSVfiles",
								"type": "DatasetReference"
							},
							"name": "Ship3Sink"
						}
					],
					"transformations": [
						{
							"name": "splitbasedoncondition"
						}
					],
					"scriptLines": [
						"source(output(",
						"          OrderID as string,",
						"          CustomerID as string,",
						"          EmployeeID as string,",
						"          OrderDate as string,",
						"          ShipperID as string",
						"     ),",
						"     allowSchemaDrift: true,",
						"     validateSchema: false,",
						"     ignoreNoFilesFound: false) ~> source1",
						"source1 split(equals(ShipperID, '1'),",
						"     equals(ShipperID, '2'),",
						"     equals(ShipperID, '3'),",
						"     disjoint: false) ~> splitbasedoncondition@(Ship1SpeedyExpress, Ship2UnitedPackage, Ship3FederalShipping)",
						"splitbasedoncondition@Ship1SpeedyExpress sink(allowSchemaDrift: true,",
						"     validateSchema: false,",
						"     partitionFileNames:['Shipper1.csv'],",
						"     skipDuplicateMapInputs: true,",
						"     skipDuplicateMapOutputs: true,",
						"     partitionBy('hash', 1)) ~> Ship1Sink",
						"splitbasedoncondition@Ship2UnitedPackage sink(allowSchemaDrift: true,",
						"     validateSchema: false,",
						"     partitionFileNames:['Shipper2.csv'],",
						"     skipDuplicateMapInputs: true,",
						"     skipDuplicateMapOutputs: true,",
						"     partitionBy('hash', 1)) ~> Ship2Sink",
						"splitbasedoncondition@Ship3FederalShipping sink(allowSchemaDrift: true,",
						"     validateSchema: false,",
						"     partitionFileNames:['Shipper3.csv'],",
						"     skipDuplicateMapInputs: true,",
						"     skipDuplicateMapOutputs: true,",
						"     partitionBy('hash', 1)) ~> Ship3Sink"
					]
				}
			},
			"dependsOn": []
		},
		{
			"name": "[concat(parameters('factoryName'), '/DerivedColumndataflow')]",
			"type": "Microsoft.DataFactory/factories/dataflows",
			"apiVersion": "2018-06-01",
			"properties": {
				"description": "updating the country column to upper case and the postal code column null values to unknown (R37)",
				"type": "MappingDataFlow",
				"typeProperties": {
					"sources": [
						{
							"dataset": {
								"referenceName": "CustomersDataset",
								"type": "DatasetReference"
							},
							"name": "source1"
						}
					],
					"sinks": [
						{
							"dataset": {
								"referenceName": "OutputDatasetCSVfiles",
								"type": "DatasetReference"
							},
							"name": "sink1"
						}
					],
					"transformations": [
						{
							"name": "derivedColumn1",
							"description": "Creating/updating the columns 'CustomerID, CustomerName, ContactName, Address, City, PostalCode, Country'"
						}
					],
					"scriptLines": [
						"source(output(",
						"          CustomerID as string,",
						"          CustomerName as string,",
						"          ContactName as string,",
						"          Address as string,",
						"          City as string,",
						"          PostalCode as string,",
						"          Country as string",
						"     ),",
						"     allowSchemaDrift: true,",
						"     validateSchema: false,",
						"     ignoreNoFilesFound: false) ~> source1",
						"source1 derive(Country = upper(Country),",
						"          PostalCode = iif(isNull(PostalCode), 'Unknown', upper(PostalCode))) ~> derivedColumn1",
						"derivedColumn1 sink(allowSchemaDrift: true,",
						"     validateSchema: false,",
						"     partitionFileNames:['Customer New.csv'],",
						"     skipDuplicateMapInputs: true,",
						"     skipDuplicateMapOutputs: true,",
						"     partitionBy('hash', 1)) ~> sink1"
					]
				}
			},
			"dependsOn": []
		},
		{
			"name": "[concat(parameters('factoryName'), '/Eistsdataflow')]",
			"type": "Microsoft.DataFactory/factories/dataflows",
			"apiVersion": "2018-06-01",
			"properties": {
				"description": "Using exits x",
				"type": "MappingDataFlow",
				"typeProperties": {
					"sources": [
						{
							"dataset": {
								"referenceName": "EmployeeDataset",
								"type": "DatasetReference"
							},
							"name": "Employee"
						},
						{
							"dataset": {
								"referenceName": "OrdersDataset",
								"type": "DatasetReference"
							},
							"name": "Orders"
						}
					],
					"sinks": [
						{
							"dataset": {
								"referenceName": "OutputDatasetCSVfiles",
								"type": "DatasetReference"
							},
							"name": "sink1",
							"rejectedDataLinkedService": {
								"referenceName": "Linkedservice_storagedemoramm",
								"type": "LinkedServiceReference"
							}
						}
					],
					"transformations": [
						{
							"name": "exists1"
						}
					],
					"scriptLines": [
						"source(output(",
						"          EmployeeID as string,",
						"          LastName as string,",
						"          FirstName as string,",
						"          BirthDate as string,",
						"          Photo as string,",
						"          Notes as string",
						"     ),",
						"     allowSchemaDrift: true,",
						"     validateSchema: false,",
						"     ignoreNoFilesFound: false) ~> Employee",
						"source(output(",
						"          OrderID as string,",
						"          CustomerID as string,",
						"          EmployeeID as string,",
						"          OrderDate as string,",
						"          ShipperID as string",
						"     ),",
						"     allowSchemaDrift: true,",
						"     validateSchema: false,",
						"     ignoreNoFilesFound: false) ~> Orders",
						"Employee, Orders exists(Employee@EmployeeID == Orders@EmployeeID,",
						"     negate:true,",
						"     partitionBy('hash', 1),",
						"     broadcast: 'auto')~> exists1",
						"exists1 sink(allowSchemaDrift: true,",
						"     validateSchema: false,",
						"     partitionFileNames:['Emp not  exists in orders table.csv'],",
						"     skipDuplicateMapInputs: true,",
						"     skipDuplicateMapOutputs: true,",
						"     partitionBy('hash', 1)) ~> sink1"
					]
				}
			},
			"dependsOn": []
		},
		{
			"name": "[concat(parameters('factoryName'), '/Filter Dataflow')]",
			"type": "Microsoft.DataFactory/factories/dataflows",
			"apiVersion": "2018-06-01",
			"properties": {
				"type": "MappingDataFlow",
				"typeProperties": {
					"sources": [
						{
							"dataset": {
								"referenceName": "CustomersDataset",
								"type": "DatasetReference"
							},
							"name": "source1"
						}
					],
					"sinks": [
						{
							"dataset": {
								"referenceName": "OutputDatasetCSVfiles",
								"type": "DatasetReference"
							},
							"name": "sink1"
						}
					],
					"transformations": [
						{
							"name": "filter1"
						}
					],
					"scriptLines": [
						"source(output(",
						"          CustomerID as string,",
						"          CustomerName as string,",
						"          ContactName as string,",
						"          Address as string,",
						"          City as string,",
						"          PostalCode as string,",
						"          Country as string",
						"     ),",
						"     allowSchemaDrift: true,",
						"     validateSchema: false,",
						"     ignoreNoFilesFound: false) ~> source1",
						"source1 filter(equals(Country, 'USA')) ~> filter1",
						"filter1 sink(allowSchemaDrift: true,",
						"     validateSchema: false,",
						"     partitionFileNames:['USA Country Filterd'],",
						"     skipDuplicateMapInputs: true,",
						"     skipDuplicateMapOutputs: true,",
						"     partitionBy('hash', 1)) ~> sink1"
					]
				}
			},
			"dependsOn": []
		}
	]
}